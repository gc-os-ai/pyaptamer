{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e85bf506",
   "metadata": {},
   "source": [
    "# Finetuning AptaNet for aptamer protein binding prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635b328",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook demonstrates how to finetune the `AptaNetClassifier` and `AptaNetRegressor` components using sklearn's hyperparameter search utilities `GridSearchCV` and `RandomizedSearchCV`. What this notebooks covers is:\n",
    "\n",
    "1. How to set up hyperparameter grids for AptaNet components\n",
    "2. Using `GridSearchCV` for exhaustive hyperparameter search\n",
    "3. Using `RandomizedSearchCV` for efficient search in larger spaces\n",
    "4. Evaluating and selecting the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e684b808",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "(same data setup as the main AptaNet tutorial)\n",
    "* Aptamer sequences of length > 30\n",
    "* Amino acid sequences from the 1GNH protein molecule\n",
    "* Binary labels indicating binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4f7d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3737da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pyaptamer.datasets import load_1gnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2f6701d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 25\n"
     ]
    }
   ],
   "source": [
    "aptamer_sequence = [\n",
    "    \"GGGAGGACGAAGACGACUCGAGACAGGCUAGGGAGGGA\",\n",
    "    \"AAGCGUCGGAUCUACACGUGCGAUAGCUCAGUACGCGGU\",\n",
    "    \"CGGUAUCGAGUACAGGAGUCCGACGGAUAGUCCGGAGC\",\n",
    "    \"UAGCUAGCGAACUAGGCGUAGCUUCGAGUAGCUACGGAA\",\n",
    "    \"GCUAGGACGAUCGCACGUGACCGUCAGUAGCGUAGGAGA\",\n",
    "]\n",
    "\n",
    "gnh = load_1gnh()\n",
    "protein_sequence = gnh.to_df_seq()[\"sequence\"].tolist()\n",
    "\n",
    "# Build all combinations (aptamer, protein), duplicated to increase dataset size\n",
    "X = [(a, p) for a in aptamer_sequence for p in protein_sequence] * 5\n",
    "\n",
    "# Dummy binary labels for the pairs\n",
    "y = torch.randint(0, 2, (len(X),), dtype=torch.float32)\n",
    "\n",
    "print(f\"Number of samples: {len(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34da132",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "Before hyperparameter tuning, we convert the sequence pairs to feature vectors. This step is done once to avoid repeated computation during cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44cc1cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (25, 690)\n"
     ]
    }
   ],
   "source": [
    "from pyaptamer.utils._aptanet_utils import pairs_to_features\n",
    "\n",
    "# Convert sequence pairs to feature vectors\n",
    "X_features = pairs_to_features(X)\n",
    "\n",
    "print(f\"Feature matrix shape: {X_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f58408",
   "metadata": {},
   "source": [
    "# 1. Aptanet Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8df48e",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with GridSearchCV\n",
    "This is ideal when you have a small set of hyperparameters to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d782bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from pyaptamer.aptanet import AptaNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8a0d947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combinations to try: 16\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    \"hidden_dim\": [64, 128],\n",
    "    \"n_hidden\": [5, 7],\n",
    "    \"dropout\": [0.2, 0.3],\n",
    "    \"lr\": [0.0001, 0.0005],\n",
    "}\n",
    "\n",
    "# Create the classifier\n",
    "clf = AptaNetClassifier(max_epochs=50, verbose=0)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=1,  #set to -1 for parallel execution\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(f\"Total combinations to try: {np.prod([len(v) for v in param_grid.values()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae896e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters: {'dropout': 0.2, 'hidden_dim': 64, 'lr': 0.0005, 'n_hidden': 7}\n",
      "Best cross-validation score: 0.6019\n"
     ]
    }
   ],
   "source": [
    "# Run grid search\n",
    "grid_search.fit(X_features, y) \n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40147f9c",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with RandomizedSearchCV\n",
    "This is ideal for larger search spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6130027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform, randint, uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a2e277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter distributions for random search\n",
    "param_distributions = {\n",
    "    \"hidden_dim\": [32, 64, 128, 256],\n",
    "    \"n_hidden\": randint(3, 10),\n",
    "    \"dropout\": uniform(0.1, 0.4),  # Uniform between 0.1 and 0.5\n",
    "    \"lr\": loguniform(1e-5, 1e-3),  # Log-uniform for learning rate\n",
    "    \"max_epochs\": [50, 100, 150],\n",
    "}\n",
    "\n",
    "# Create the classifier\n",
    "clf = AptaNetClassifier(verbose=0)\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=clf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,  # Number of random combinations to try\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=1,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8049a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "\n",
      "Best parameters: {'dropout': np.float64(0.30990986410335564), 'hidden_dim': 128, 'lr': np.float64(1.9010245319870364e-05), 'max_epochs': 150, 'n_hidden': 8}\n",
      "Best cross-validation score: 0.6019\n"
     ]
    }
   ],
   "source": [
    "# Run the random search\n",
    "random_search.fit(X_features, y)\n",
    "\n",
    "print(f\"\\nBest parameters: {random_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {random_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94bcaaa",
   "metadata": {},
   "source": [
    "## Evaluating the best model\n",
    "After hyperparameter tuning, use the best estimator for final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "523f4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0cf0bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      1.00      0.75        15\n",
      "         1.0       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.30      0.50      0.38        25\n",
      "weighted avg       0.36      0.60      0.45        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the best estimator from random search\n",
    "best_clf = random_search.best_estimator_\n",
    "\n",
    "#predictions\n",
    "y_pred = best_clf.predict(X_features)\n",
    "\n",
    "print(f\"Training Accuracy: {accuracy_score(y, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc8a87",
   "metadata": {},
   "source": [
    "## Using the full AptaNetPipeline with tuned parameters\n",
    "Once the best hyperparameters are found, we can use them with the full pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ed76399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Training Accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "from pyaptamer.aptanet import AptaNetClassifier, AptaNetPipeline\n",
    "\n",
    "# Create a classifier with the best parameters\n",
    "best_params = random_search.best_params_\n",
    "tuned_clf = AptaNetClassifier(**best_params, verbose=0)\n",
    "\n",
    "# Use it in the full pipeline (which handles feature extraction)\n",
    "pipeline = AptaNetPipeline(estimator=tuned_clf)\n",
    "\n",
    "# Fit on the original sequence pairs (not pre-extracted features)\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X)\n",
    "print(f\"Pipeline Training Accuracy: {accuracy_score(y, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c678719",
   "metadata": {},
   "source": [
    "## 2. AptaNetRegressor\n",
    "\n",
    "The same finetuning approach works for *AptaNetRegressor*. Just replace:\n",
    "1. AptaNetClassifier() to AptaNetRegressor()  \n",
    "2. `scoring=\"accuracy\"` to `scoring=\"r2\"` (or `\"neg_mean_squared_error\"`)\n",
    "\n",
    "The hyperparameter grid remains the same (`hidden_dim`, `n_hidden`, `dropout`, `lr`, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
