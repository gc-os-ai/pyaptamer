{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e8d179",
   "metadata": {},
   "source": [
    "# Binding prediction using AptaNet\n",
    "Step-by-step guide to using AptaNet for binary aptamer–protein binding prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a64683",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- **pairs_to_features**: converts `(aptamer_seq, protein_seq)` pairs into feature vectors using k-mer + PSeAAC.\n",
    "- **FeatureSelector**: a Random Forest-based transformer that selects important features.\n",
    "- **SkorchAptaNet**: a PyTorch MLP wrapped in Skorch for binary classification with a configurable threshold.\n",
    "- **load_pfoa_structure**: helper to load PFOA molecule structure from PDB file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a5052",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Import the core functions and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15eabec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import torch  # noqa: I001\n",
    "import torch.optim as optim\n",
    "\n",
    "# Data imports\n",
    "from pyaptamer.datasets.loader import load_1gnh_structure\n",
    "from pyaptamer.utils.struct_to_aaseq import struct_to_aaseq\n",
    "\n",
    "# If you want to use the aptamer pipeline, you should use the following imports\n",
    "from pyaptamer.aptanet.pipeline import pipe\n",
    "\n",
    "# If you to build your own aptamer pipeline, you should use the following imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pyaptamer.aptanet import FeatureSelector, SkorchAptaNet\n",
    "from pyaptamer.utils._aptanet_utils import pairs_to_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c592d9",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "To train the skorch network the notebook uses:\n",
    "* As `X`:\n",
    "    * 5 random aptamer sequences of length>30 (to satisfy the default lambda value of 30 set in the PSeAAC algorithm).\n",
    "    * Amino-acid sequences extracted from the 1GNH protein molecule.\n",
    "* As `y`:\n",
    " * A random binary value (0/1) equal to the number of `(aptamer_seq, protein_seq)` pairs as dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2f6701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_sequences = [\n",
    "    \"GGGAGGACGAAGACGACUCGAGACAGGCUAGGGAGGGA\",\n",
    "    \"AAGCGUCGGAUCUACACGUGCGAUAGCUCAGUACGCGGU\",\n",
    "    \"CGGUAUCGAGUACAGGAGUCCGACGGAUAGUCCGGAGC\",\n",
    "    \"UAGCUAGCGAACUAGGCGUAGCUUCGAGUAGCUACGGAA\",\n",
    "    \"GCUAGGACGAUCGCACGUGACCGUCAGUAGCGUAGGAGA\",\n",
    "]\n",
    "\n",
    "gnh = load_1gnh_structure()\n",
    "protein_sequence = struct_to_aaseq(gnh)\n",
    "\n",
    "unique_proteins = list(set(protein_sequence))\n",
    "unique_aptamers = list(set(aptamer_sequences))\n",
    "\n",
    "# Build all combinations (protein, aptamer)\n",
    "X = [(a, p) for a in unique_aptamers for p in unique_proteins]\n",
    "\n",
    "# Dummy binary labels for the pairs\n",
    "y = torch.randint(0, 2, (len(X),))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd459190",
   "metadata": {},
   "source": [
    "## Build your own pipeline\n",
    " To build a scikit-learn pipeline, follow these steps:\n",
    "1. Convert the input to the desired (aptamer_sequence, protein_sequence) format.\n",
    "    * OPTIONAL: As mentioned in the paper, perform under-sampling using the  \n",
    "    Neighborhood Cleaning Rule to balance the classes.\n",
    "2. Get the PSeAAC feature vectors for your converted input (using `pairs_to_features`).\n",
    "3. Select the number of features to use from the feature vector (using `FeatureSelector`).\n",
    "4. Define the skorch neural network (using `SkorchAptaNet`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0cf0bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: If you want to use the Neighborhood Cleaning Rule for under-sampling\n",
    "# %pip install imblearn\n",
    "# from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "\n",
    "# ncr = NeighbourhoodCleaningRule()\n",
    "# X, y = ncr.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13fb1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifier\n",
    "net = SkorchAptaNet(\n",
    "    module__hidden_dim=128,\n",
    "    module__n_hidden=7,\n",
    "    module__dropout=0.3,\n",
    "    max_epochs=200,\n",
    "    lr=1.4e-4,\n",
    "    batch_size=310,\n",
    "    optimizer=optim.RMSprop,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    threshold=0.5,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Option 1: build a new pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"features\", pairs_to_features),\n",
    "        (\"selector\", FeatureSelector()),\n",
    "        (\"clf\", net),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Option 2: import the pre-defined pipeline (which does the same)\n",
    "pipeline = pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d70138a",
   "metadata": {},
   "source": [
    "## Model Training and Prediction\n",
    "\n",
    "Now that we’ve defined our AptaNet pipeline, we proceed to train the model, and use it to predict, on our aptamer-protein dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ed76399",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_splits=5 cannot be greater than the number of members in each class.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Fit the pipeline on the aptamer-protein pairs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Predict the labels for the training data\u001b[39;00m\n\u001b[32m      5\u001b[39m y_pred = pipeline.predict(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer\\Lib\\site-packages\\sklearn\\pipeline.py:663\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    658\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    659\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    660\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    661\u001b[39m             all_params=params,\n\u001b[32m    662\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer\\Lib\\site-packages\\skorch\\classifier.py:348\u001b[39m, in \u001b[36mNeuralNetBinaryClassifier.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"See ``NeuralNet.fit``.\u001b[39;00m\n\u001b[32m    338\u001b[39m \n\u001b[32m    339\u001b[39m \u001b[33;03mIn contrast to ``NeuralNet.fit``, ``y`` is non-optional to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# this is actually a pylint bug:\u001b[39;00m\n\u001b[32m    347\u001b[39m \u001b[38;5;66;03m# https://github.com/PyCQA/pylint/issues/1085\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer\\Lib\\site-packages\\skorch\\net.py:1349\u001b[39m, in \u001b[36mNeuralNet.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.warm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.initialized_:\n\u001b[32m   1347\u001b[39m     \u001b[38;5;28mself\u001b[39m.initialize()\n\u001b[32m-> \u001b[39m\u001b[32m1349\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1350\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer\\Lib\\site-packages\\skorch\\net.py:1308\u001b[39m, in \u001b[36mNeuralNet.partial_fit\u001b[39m\u001b[34m(self, X, y, classes, **fit_params)\u001b[39m\n\u001b[32m   1306\u001b[39m \u001b[38;5;28mself\u001b[39m.notify(\u001b[33m'\u001b[39m\u001b[33mon_train_begin\u001b[39m\u001b[33m'\u001b[39m, X=X, y=y)\n\u001b[32m   1307\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1308\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer\\Lib\\site-packages\\skorch\\net.py:1206\u001b[39m, in \u001b[36mNeuralNet.fit_loop\u001b[39m\u001b[34m(self, X, y, epochs, **fit_params)\u001b[39m\n\u001b[32m   1203\u001b[39m \u001b[38;5;28mself\u001b[39m.check_training_readiness()\n\u001b[32m   1204\u001b[39m epochs = epochs \u001b[38;5;28;01mif\u001b[39;00m epochs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.max_epochs\n\u001b[32m-> \u001b[39m\u001b[32m1206\u001b[39m dataset_train, dataset_valid = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_split_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1208\u001b[39m on_epoch_kwargs = {\n\u001b[32m   1209\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdataset_train\u001b[39m\u001b[33m'\u001b[39m: dataset_train,\n\u001b[32m   1210\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdataset_valid\u001b[39m\u001b[33m'\u001b[39m: dataset_valid,\n\u001b[32m   1211\u001b[39m }\n\u001b[32m   1212\u001b[39m iterator_train = \u001b[38;5;28mself\u001b[39m.get_iterator(dataset_train, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer\\Lib\\site-packages\\skorch\\net.py:1801\u001b[39m, in \u001b[36mNeuralNet.get_split_datasets\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m   1798\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1799\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.train_split(dataset, **fit_params)\n\u001b[32m-> \u001b[39m\u001b[32m1801\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer\\Lib\\site-packages\\skorch\\dataset.py:326\u001b[39m, in \u001b[36mValidSplit.__call__\u001b[39m\u001b[34m(self, dataset, y, groups)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_stratified(cv):\n\u001b[32m    324\u001b[39m     args = args + (to_numpy(y),)\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m idx_train, idx_valid = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    327\u001b[39m dataset_train = torch.utils.data.Subset(dataset, idx_train)\n\u001b[32m    328\u001b[39m dataset_valid = torch.utils.data.Subset(dataset, idx_valid)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:411\u001b[39m, in \u001b[36m_BaseKFold.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_splits > n_samples:\n\u001b[32m    404\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    405\u001b[39m         (\n\u001b[32m    406\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m greater\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    408\u001b[39m         ).format(\u001b[38;5;28mself\u001b[39m.n_splits, n_samples)\n\u001b[32m    409\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:142\u001b[39m, in \u001b[36mBaseCrossValidator.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m    140\u001b[39m X, y, groups = indexable(X, y, groups)\n\u001b[32m    141\u001b[39m indices = np.arange(_num_samples(X))\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_test_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogical_not\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:844\u001b[39m, in \u001b[36mStratifiedKFold._iter_test_masks\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m, groups=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m844\u001b[39m     test_folds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_test_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.n_splits):\n\u001b[32m    846\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m test_folds == i\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:806\u001b[39m, in \u001b[36mStratifiedKFold._make_test_folds\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    804\u001b[39m min_groups = np.min(y_counts)\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.all(\u001b[38;5;28mself\u001b[39m.n_splits > y_counts):\n\u001b[32m--> \u001b[39m\u001b[32m806\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    807\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mn_splits=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m cannot be greater than the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    808\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m number of members in each class.\u001b[39m\u001b[33m\"\u001b[39m % (\u001b[38;5;28mself\u001b[39m.n_splits)\n\u001b[32m    809\u001b[39m     )\n\u001b[32m    810\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_splits > min_groups:\n\u001b[32m    811\u001b[39m     warnings.warn(\n\u001b[32m    812\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe least populated class in y has only \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    813\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m members, which is less than n_splits=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    814\u001b[39m         % (min_groups, \u001b[38;5;28mself\u001b[39m.n_splits),\n\u001b[32m    815\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    816\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: n_splits=5 cannot be greater than the number of members in each class."
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the aptamer-protein pairs\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945dc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Evaluate training accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyaptamer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
