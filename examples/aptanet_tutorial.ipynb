{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e8d179",
   "metadata": {},
   "source": [
    "# Binding prediction using AptaNet\n",
    "Step-by-step guide to using AptaNet for binary aptamerâ€“protein binding prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a64683",
   "metadata": {},
   "source": [
    "## Overview\n",
    "- **pairs_to_features**: converts `(aptamer_seq, protein_seq)` pairs into feature vectors using k-mer + PSeAAC.\n",
    "- **FeatureSelector**: a Random Forest-based transformer that selects important features.\n",
    "- **SkorchAptaNet**: a PyTorch MLP wrapped in Skorch for binary classification with a configurable threshold.\n",
    "- **load_pfoa_structure**: helper to load PFOA molecule structure from PDB file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a5052",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Import the core functions and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15eabec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import torch  # noqa: I001\n",
    "\n",
    "# Data imports\n",
    "from pyaptamer.datasets import load_1gnh_structure\n",
    "from pyaptamer.utils.struct_to_aaseq import struct_to_aaseq\n",
    "\n",
    "# If you want to use the AptaNet pipeline, you can import it directly\n",
    "from pyaptamer.aptanet import AptaNetPipeline\n",
    "\n",
    "# If you to build your own aptamer pipeline, you should use the following imports\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from pyaptamer.utils._aptanet_utils import pairs_to_features\n",
    "from pyaptamer.aptanet._aptanet_nn import AptaNetMLP\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c592d9",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "To train the skorch network the notebook uses:\n",
    "* As `X`:\n",
    "    * 5 random aptamer sequences of length>30 (to satisfy the default lambda value of 30 set in the PSeAAC algorithm).\n",
    "    * Amino-acid sequences extracted from the 1GNH protein molecule.\n",
    "* As `y`:\n",
    "    * A random binary value (0/1) equal to the number of `(aptamer_seq, protein_seq)` pairs as dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f6701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_sequence = [\n",
    "    \"GGGAGGACGAAGACGACUCGAGACAGGCUAGGGAGGGA\",\n",
    "    \"AAGCGUCGGAUCUACACGUGCGAUAGCUCAGUACGCGGU\",\n",
    "    \"CGGUAUCGAGUACAGGAGUCCGACGGAUAGUCCGGAGC\",\n",
    "    \"UAGCUAGCGAACUAGGCGUAGCUUCGAGUAGCUACGGAA\",\n",
    "    \"GCUAGGACGAUCGCACGUGACCGUCAGUAGCGUAGGAGA\",\n",
    "]\n",
    "\n",
    "gnh = load_1gnh_structure()\n",
    "protein_sequence = struct_to_aaseq(gnh)\n",
    "\n",
    "# Build all combinations (aptamer, protein)\n",
    "X = [(a, p) for a in aptamer_sequence for p in protein_sequence]\n",
    "\n",
    "# Dummy binary labels for the pairs\n",
    "y = torch.randint(0, 2, (len(X),), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd459190",
   "metadata": {},
   "source": [
    "## Build your own pipeline\n",
    " To build a scikit-learn pipeline, follow these steps:\n",
    "1. Convert the input to the desired (aptamer_sequence, protein_sequence) format.\n",
    "    * OPTIONAL: As mentioned in the paper, perform under-sampling using the  \n",
    "    Neighborhood Cleaning Rule to balance the classes.\n",
    "2. Get the PSeAAC feature vectors for your converted input (using `pairs_to_features`).\n",
    "3. Select the number of features to use from the feature vector (using `FeatureSelector`).\n",
    "4. Define the skorch neural network (using `AptaNetMLP`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ae4ea",
   "metadata": {},
   "source": [
    "## Different workflows\n",
    "In this notebook we will cover 2 different workflows one can follow, in ascending order of customizability:\n",
    "\n",
    "1. A minimal workflow with no dataset balancing, while using the in-built pipeline.\n",
    "2. Using your own custom pipeline.\n",
    "3. Dataset balancing using under-sampling, while using your own pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c1997",
   "metadata": {},
   "source": [
    "### First workflow\n",
    "A minimal workflow with no dataset balancing, while using the in-built pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d782bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AptaNetPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a0d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline on the aptamer-protein pairs\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae896e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Optional: Evaluate training accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a04f9",
   "metadata": {},
   "source": [
    "### Second Worflow\n",
    "\n",
    "Your own custom-built pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a2e277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_transformer = FunctionTransformer(\n",
    "    func=pairs_to_features,\n",
    "    validate=False,\n",
    "    # Optional arguments for pairs_to_features\n",
    "    # example: kw_args={'k': 4, 'pseaac_kwargs': {'lambda_value': 30}}\n",
    "    kw_args={},\n",
    ")\n",
    "\n",
    "selector = SelectFromModel(\n",
    "    estimator=RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=9,\n",
    "        random_state=None,\n",
    "    ),\n",
    "    threshold=\"mean\",\n",
    ")\n",
    "\n",
    "# Define the classifier\n",
    "net = NeuralNetBinaryClassifier(\n",
    "    module=AptaNetMLP,\n",
    "    module__input_dim=None,\n",
    "    module__hidden_dim=128,\n",
    "    module__n_hidden=7,\n",
    "    module__dropout=0.3,\n",
    "    module__output_dim=1,\n",
    "    module__use_lazy=True,\n",
    "    criterion=torch.nn.BCEWithLogitsLoss,\n",
    "    max_epochs=200,\n",
    "    lr=0.00014,\n",
    "    optimizer=torch.optim.RMSprop,\n",
    "    optimizer__alpha=0.9,\n",
    "    optimizer__eps=1e-08,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"features\", feature_transformer),\n",
    "        (\"selector\", selector),\n",
    "        (\"clf\", net),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8049a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6890\u001b[0m       \u001b[32m0.4000\u001b[0m        \u001b[35m0.7016\u001b[0m  0.0100\n",
      "      2        0.7427       0.4000        \u001b[35m0.7015\u001b[0m  0.0110\n",
      "      3        0.7637       0.4000        \u001b[35m0.7014\u001b[0m  0.0100\n",
      "      4        \u001b[36m0.6811\u001b[0m       0.4000        \u001b[35m0.7014\u001b[0m  0.0085\n",
      "      5        0.7387       0.4000        \u001b[35m0.7013\u001b[0m  0.0090\n",
      "      6        0.7823       0.4000        \u001b[35m0.7012\u001b[0m  0.0100\n",
      "      7        0.7878       0.4000        \u001b[35m0.7012\u001b[0m  0.0100\n",
      "      8        0.7345       0.4000        \u001b[35m0.7012\u001b[0m  0.0100\n",
      "      9        0.7311       0.4000        \u001b[35m0.7011\u001b[0m  0.0090\n",
      "     10        0.7584       0.4000        \u001b[35m0.7010\u001b[0m  0.0110\n",
      "     11        0.7218       0.4000        \u001b[35m0.7010\u001b[0m  0.0100\n",
      "     12        0.7060       0.4000        0.7010  0.0095\n",
      "     13        \u001b[36m0.6442\u001b[0m       0.4000        0.7010  0.0090\n",
      "     14        0.7207       0.4000        \u001b[35m0.7010\u001b[0m  0.0090\n",
      "     15        0.6696       0.4000        \u001b[35m0.7009\u001b[0m  0.0100\n",
      "     16        0.7840       0.4000        \u001b[35m0.7009\u001b[0m  0.0110\n",
      "     17        0.6857       0.4000        \u001b[35m0.7008\u001b[0m  0.0100\n",
      "     18        0.7446       0.4000        \u001b[35m0.7007\u001b[0m  0.0100\n",
      "     19        0.7197       0.4000        \u001b[35m0.7007\u001b[0m  0.0100\n",
      "     20        0.7466       0.4000        \u001b[35m0.7006\u001b[0m  0.0105\n",
      "     21        0.6807       0.4000        \u001b[35m0.7006\u001b[0m  0.0100\n",
      "     22        0.7144       0.4000        \u001b[35m0.7005\u001b[0m  0.0100\n",
      "     23        0.7257       0.4000        \u001b[35m0.7005\u001b[0m  0.0080\n",
      "     24        0.6844       0.4000        \u001b[35m0.7004\u001b[0m  0.0140\n",
      "     25        0.7192       0.4000        \u001b[35m0.7004\u001b[0m  0.0140\n",
      "     26        0.7205       0.4000        \u001b[35m0.7004\u001b[0m  0.0140\n",
      "     27        0.6734       0.4000        \u001b[35m0.7004\u001b[0m  0.0105\n",
      "     28        0.7618       0.4000        \u001b[35m0.7003\u001b[0m  0.0090\n",
      "     29        0.7076       0.4000        \u001b[35m0.7002\u001b[0m  0.0090\n",
      "     30        0.7194       0.4000        \u001b[35m0.7002\u001b[0m  0.0100\n",
      "     31        0.7058       0.4000        \u001b[35m0.7001\u001b[0m  0.0100\n",
      "     32        0.8121       0.4000        \u001b[35m0.7000\u001b[0m  0.0080\n",
      "     33        0.7104       0.4000        \u001b[35m0.7000\u001b[0m  0.0090\n",
      "     34        \u001b[36m0.6363\u001b[0m       0.4000        \u001b[35m0.7000\u001b[0m  0.0100\n",
      "     35        0.6808       0.4000        \u001b[35m0.6999\u001b[0m  0.0100\n",
      "     36        0.7812       0.4000        \u001b[35m0.6999\u001b[0m  0.0095\n",
      "     37        0.7070       0.4000        \u001b[35m0.6998\u001b[0m  0.0080\n",
      "     38        0.7948       0.4000        \u001b[35m0.6998\u001b[0m  0.0080\n",
      "     39        0.7321       0.4000        \u001b[35m0.6997\u001b[0m  0.0090\n",
      "     40        0.7270       0.4000        \u001b[35m0.6997\u001b[0m  0.0100\n",
      "     41        0.8074       0.4000        \u001b[35m0.6996\u001b[0m  0.0080\n",
      "     42        0.7517       0.4000        \u001b[35m0.6996\u001b[0m  0.0080\n",
      "     43        0.6999       0.4000        \u001b[35m0.6995\u001b[0m  0.0090\n",
      "     44        0.6839       0.4000        \u001b[35m0.6995\u001b[0m  0.0070\n",
      "     45        0.7796       0.4000        0.6995  0.0095\n",
      "     46        0.6938       0.4000        \u001b[35m0.6995\u001b[0m  0.0080\n",
      "     47        0.6800       0.4000        0.6995  0.0090\n",
      "     48        0.8033       0.4000        \u001b[35m0.6995\u001b[0m  0.0090\n",
      "     49        0.6777       0.4000        0.6995  0.0080\n",
      "     50        0.7241       0.4000        \u001b[35m0.6994\u001b[0m  0.0090\n",
      "     51        0.7281       0.4000        \u001b[35m0.6994\u001b[0m  0.0080\n",
      "     52        0.7141       0.4000        \u001b[35m0.6994\u001b[0m  0.0090\n",
      "     53        0.6428       0.4000        \u001b[35m0.6993\u001b[0m  0.0090\n",
      "     54        0.7222       0.4000        \u001b[35m0.6993\u001b[0m  0.0090\n",
      "     55        0.7479       0.4000        \u001b[35m0.6992\u001b[0m  0.0085\n",
      "     56        0.7326       0.4000        \u001b[35m0.6992\u001b[0m  0.0080\n",
      "     57        0.7133       0.4000        \u001b[35m0.6992\u001b[0m  0.0090\n",
      "     58        0.6875       0.4000        \u001b[35m0.6991\u001b[0m  0.0090\n",
      "     59        0.6990       0.4000        \u001b[35m0.6991\u001b[0m  0.0080\n",
      "     60        0.6856       0.4000        \u001b[35m0.6991\u001b[0m  0.0080\n",
      "     61        0.7102       0.4000        \u001b[35m0.6991\u001b[0m  0.0080\n",
      "     62        0.7069       0.4000        \u001b[35m0.6990\u001b[0m  0.0070\n",
      "     63        0.7897       0.4000        \u001b[35m0.6989\u001b[0m  0.0070\n",
      "     64        0.7686       0.4000        \u001b[35m0.6989\u001b[0m  0.0070\n",
      "     65        0.7123       0.4000        \u001b[35m0.6988\u001b[0m  0.0095\n",
      "     66        0.7072       0.4000        \u001b[35m0.6988\u001b[0m  0.0090\n",
      "     67        0.7795       0.4000        \u001b[35m0.6987\u001b[0m  0.0070\n",
      "     68        0.7023       0.4000        \u001b[35m0.6987\u001b[0m  0.0090\n",
      "     69        0.7164       0.4000        \u001b[35m0.6987\u001b[0m  0.0070\n",
      "     70        0.7049       0.4000        \u001b[35m0.6986\u001b[0m  0.0080\n",
      "     71        0.6982       0.4000        \u001b[35m0.6986\u001b[0m  0.0090\n",
      "     72        0.7328       0.4000        \u001b[35m0.6985\u001b[0m  0.0080\n",
      "     73        0.7696       0.4000        \u001b[35m0.6985\u001b[0m  0.0070\n",
      "     74        0.7290       0.4000        \u001b[35m0.6985\u001b[0m  0.0080\n",
      "     75        0.7299       0.4000        \u001b[35m0.6984\u001b[0m  0.0085\n",
      "     76        0.6854       0.4000        \u001b[35m0.6984\u001b[0m  0.0080\n",
      "     77        0.7252       0.4000        \u001b[35m0.6984\u001b[0m  0.0080\n",
      "     78        0.7024       0.4000        \u001b[35m0.6983\u001b[0m  0.0070\n",
      "     79        0.6999       0.4000        \u001b[35m0.6983\u001b[0m  0.0080\n",
      "     80        0.7456       0.4000        0.6983  0.0080\n",
      "     81        0.7281       0.4000        \u001b[35m0.6983\u001b[0m  0.0080\n",
      "     82        0.6772       0.4000        \u001b[35m0.6982\u001b[0m  0.0080\n",
      "     83        0.6823       0.4000        \u001b[35m0.6982\u001b[0m  0.0090\n",
      "     84        0.6919       0.4000        \u001b[35m0.6981\u001b[0m  0.0080\n",
      "     85        0.7267       0.4000        \u001b[35m0.6981\u001b[0m  0.0084\n",
      "     86        0.7363       0.4000        \u001b[35m0.6980\u001b[0m  0.0080\n",
      "     87        0.7094       0.4000        \u001b[35m0.6980\u001b[0m  0.0070\n",
      "     88        0.7094       0.4000        \u001b[35m0.6980\u001b[0m  0.0080\n",
      "     89        0.7359       0.4000        \u001b[35m0.6979\u001b[0m  0.0080\n",
      "     90        0.7691       0.4000        \u001b[35m0.6979\u001b[0m  0.0080\n",
      "     91        0.6875       0.4000        0.6979  0.0080\n",
      "     92        0.6834       0.4000        0.6979  0.0080\n",
      "     93        0.8027       0.4000        \u001b[35m0.6979\u001b[0m  0.0090\n",
      "     94        0.6902       0.4000        \u001b[35m0.6978\u001b[0m  0.0080\n",
      "     95        0.7298       0.4000        \u001b[35m0.6978\u001b[0m  0.0075\n",
      "     96        0.6992       0.4000        \u001b[35m0.6978\u001b[0m  0.0080\n",
      "     97        0.7084       0.4000        \u001b[35m0.6978\u001b[0m  0.0090\n",
      "     98        0.6797       0.4000        \u001b[35m0.6977\u001b[0m  0.0070\n",
      "     99        0.7397       0.4000        \u001b[35m0.6977\u001b[0m  0.0080\n",
      "    100        0.7153       0.4000        \u001b[35m0.6976\u001b[0m  0.0080\n",
      "    101        0.7464       0.4000        \u001b[35m0.6976\u001b[0m  0.0080\n",
      "    102        0.7225       0.4000        \u001b[35m0.6975\u001b[0m  0.0080\n",
      "    103        0.6787       0.4000        0.6975  0.0090\n",
      "    104        0.7749       0.4000        \u001b[35m0.6975\u001b[0m  0.0080\n",
      "    105        0.7514       0.4000        \u001b[35m0.6975\u001b[0m  0.0080\n",
      "    106        0.7452       0.4000        \u001b[35m0.6974\u001b[0m  0.0080\n",
      "    107        0.6965       0.4000        \u001b[35m0.6973\u001b[0m  0.0070\n",
      "    108        0.7162       0.4000        0.6973  0.0070\n",
      "    109        0.7303       0.4000        0.6974  0.0080\n",
      "    110        0.7060       0.4000        \u001b[35m0.6973\u001b[0m  0.0080\n",
      "    111        0.7042       0.4000        \u001b[35m0.6973\u001b[0m  0.0090\n",
      "    112        0.7360       0.4000        \u001b[35m0.6973\u001b[0m  0.0070\n",
      "    113        0.7340       0.4000        \u001b[35m0.6972\u001b[0m  0.0090\n",
      "    114        0.6930       0.4000        \u001b[35m0.6972\u001b[0m  0.0070\n",
      "    115        0.6890       0.4000        \u001b[35m0.6971\u001b[0m  0.0080\n",
      "    116        0.6998       0.4000        0.6972  0.0080\n",
      "    117        0.7512       0.4000        \u001b[35m0.6971\u001b[0m  0.0080\n",
      "    118        0.7183       0.4000        0.6971  0.0080\n",
      "    119        0.7615       0.4000        0.6971  0.0070\n",
      "    120        0.7001       0.4000        0.6971  0.0080\n",
      "    121        0.7531       0.4000        \u001b[35m0.6971\u001b[0m  0.0080\n",
      "    122        0.6845       0.4000        \u001b[35m0.6970\u001b[0m  0.0070\n",
      "    123        0.7525       0.4000        \u001b[35m0.6970\u001b[0m  0.0080\n",
      "    124        0.7443       0.4000        \u001b[35m0.6970\u001b[0m  0.0080\n",
      "    125        0.7809       0.4000        \u001b[35m0.6970\u001b[0m  0.0090\n",
      "    126        0.6985       0.4000        \u001b[35m0.6970\u001b[0m  0.0080\n",
      "    127        0.7089       0.4000        \u001b[35m0.6970\u001b[0m  0.0080\n",
      "    128        0.7173       0.4000        \u001b[35m0.6969\u001b[0m  0.0080\n",
      "    129        0.7192       0.4000        \u001b[35m0.6969\u001b[0m  0.0080\n",
      "    130        0.7552       0.4000        \u001b[35m0.6968\u001b[0m  0.0090\n",
      "    131        0.7347       0.4000        \u001b[35m0.6968\u001b[0m  0.0080\n",
      "    132        0.7061       0.4000        \u001b[35m0.6968\u001b[0m  0.0090\n",
      "    133        0.7332       0.4000        \u001b[35m0.6968\u001b[0m  0.0080\n",
      "    134        0.7582       0.4000        \u001b[35m0.6968\u001b[0m  0.0090\n",
      "    135        0.7402       0.4000        \u001b[35m0.6967\u001b[0m  0.0085\n",
      "    136        0.6849       0.4000        \u001b[35m0.6967\u001b[0m  0.0080\n",
      "    137        0.7031       0.4000        \u001b[35m0.6966\u001b[0m  0.0080\n",
      "    138        0.7213       0.4000        \u001b[35m0.6966\u001b[0m  0.0080\n",
      "    139        0.7110       0.4000        \u001b[35m0.6966\u001b[0m  0.0090\n",
      "    140        0.7242       0.4000        \u001b[35m0.6966\u001b[0m  0.0100\n",
      "    141        0.7552       0.4000        \u001b[35m0.6965\u001b[0m  0.0070\n",
      "    142        0.8314       0.4000        0.6965  0.0070\n",
      "    143        0.6989       0.4000        \u001b[35m0.6965\u001b[0m  0.0070\n",
      "    144        0.7184       0.4000        \u001b[35m0.6965\u001b[0m  0.0070\n",
      "    145        0.6704       0.4000        \u001b[35m0.6965\u001b[0m  0.0105\n",
      "    146        0.7826       0.4000        \u001b[35m0.6964\u001b[0m  0.0080\n",
      "    147        0.7705       0.4000        0.6965  0.0090\n",
      "    148        0.7239       0.4000        \u001b[35m0.6964\u001b[0m  0.0070\n",
      "    149        0.6792       0.4000        \u001b[35m0.6964\u001b[0m  0.0090\n",
      "    150        0.6656       0.4000        \u001b[35m0.6964\u001b[0m  0.0080\n",
      "    151        0.7407       0.4000        \u001b[35m0.6964\u001b[0m  0.0080\n",
      "    152        0.6629       0.4000        \u001b[35m0.6963\u001b[0m  0.0090\n",
      "    153        0.7347       0.4000        \u001b[35m0.6963\u001b[0m  0.0090\n",
      "    154        0.7351       0.4000        \u001b[35m0.6962\u001b[0m  0.0080\n",
      "    155        0.6953       0.4000        0.6963  0.0090\n",
      "    156        0.7035       0.4000        0.6963  0.0070\n",
      "    157        0.7368       0.4000        \u001b[35m0.6962\u001b[0m  0.0080\n",
      "    158        0.7422       0.4000        0.6962  0.0070\n",
      "    159        0.7366       0.4000        \u001b[35m0.6962\u001b[0m  0.0080\n",
      "    160        0.6942       0.4000        \u001b[35m0.6961\u001b[0m  0.0070\n",
      "    161        0.7097       0.4000        \u001b[35m0.6961\u001b[0m  0.0080\n",
      "    162        0.6536       0.4000        \u001b[35m0.6961\u001b[0m  0.0080\n",
      "    163        0.6801       0.4000        \u001b[35m0.6960\u001b[0m  0.0080\n",
      "    164        0.7260       0.4000        \u001b[35m0.6960\u001b[0m  0.0090\n",
      "    165        0.6771       0.4000        \u001b[35m0.6960\u001b[0m  0.0091\n",
      "    166        0.6410       0.4000        \u001b[35m0.6959\u001b[0m  0.0090\n",
      "    167        0.7384       0.4000        \u001b[35m0.6959\u001b[0m  0.0090\n",
      "    168        0.7890       0.4000        \u001b[35m0.6959\u001b[0m  0.0080\n",
      "    169        0.8106       0.4000        0.6959  0.0090\n",
      "    170        0.6920       0.4000        \u001b[35m0.6959\u001b[0m  0.0100\n",
      "    171        0.7512       0.4000        0.6959  0.0080\n",
      "    172        0.6897       0.4000        0.6959  0.0100\n",
      "    173        0.7000       0.4000        \u001b[35m0.6959\u001b[0m  0.0080\n",
      "    174        0.7104       0.4000        \u001b[35m0.6958\u001b[0m  0.0080\n",
      "    175        0.7315       0.4000        0.6959  0.0090\n",
      "    176        0.7166       0.4000        \u001b[35m0.6958\u001b[0m  0.0080\n",
      "    177        0.7347       0.4000        \u001b[35m0.6958\u001b[0m  0.0080\n",
      "    178        0.7554       0.4000        \u001b[35m0.6958\u001b[0m  0.0080\n",
      "    179        0.7655       0.4000        \u001b[35m0.6957\u001b[0m  0.0080\n",
      "    180        0.6934       0.4000        0.6958  0.0080\n",
      "    181        0.7266       0.4000        \u001b[35m0.6957\u001b[0m  0.0080\n",
      "    182        0.7219       0.4000        \u001b[35m0.6957\u001b[0m  0.0080\n",
      "    183        0.6859       0.4000        \u001b[35m0.6957\u001b[0m  0.0080\n",
      "    184        0.7054       0.4000        0.6957  0.0070\n",
      "    185        0.7027       0.4000        \u001b[35m0.6957\u001b[0m  0.0090\n",
      "    186        \u001b[36m0.6306\u001b[0m       0.4000        \u001b[35m0.6957\u001b[0m  0.0090\n",
      "    187        0.7256       0.4000        \u001b[35m0.6956\u001b[0m  0.0090\n",
      "    188        0.6773       0.4000        \u001b[35m0.6956\u001b[0m  0.0080\n",
      "    189        0.7371       0.4000        \u001b[35m0.6956\u001b[0m  0.0090\n",
      "    190        0.7497       0.4000        \u001b[35m0.6956\u001b[0m  0.0090\n",
      "    191        0.7792       0.4000        0.6956  0.0090\n",
      "    192        0.6772       0.4000        \u001b[35m0.6955\u001b[0m  0.0080\n",
      "    193        0.7193       0.4000        \u001b[35m0.6955\u001b[0m  0.0080\n",
      "    194        0.7417       0.4000        \u001b[35m0.6955\u001b[0m  0.0081\n",
      "    195        0.7153       0.4000        \u001b[35m0.6955\u001b[0m  0.0090\n",
      "    196        0.7465       0.4000        \u001b[35m0.6955\u001b[0m  0.0070\n",
      "    197        0.6904       0.4000        \u001b[35m0.6954\u001b[0m  0.0090\n",
      "    198        0.7211       0.4000        \u001b[35m0.6954\u001b[0m  0.0070\n",
      "    199        0.7027       0.4000        \u001b[35m0.6954\u001b[0m  0.0080\n",
      "    200        0.6752       0.4000        \u001b[35m0.6954\u001b[0m  0.0090\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the aptamer-protein pairs\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f00091db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.48\n"
     ]
    }
   ],
   "source": [
    "# Optional: Evaluate training accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db693e",
   "metadata": {},
   "source": [
    "### Third workflow\n",
    "Dataset balancing using under-sampling, while using your own pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cf0bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: If you want to use the Neighborhood Cleaning Rule for under-sampling\n",
    "# NOTE: If you want to use the under-sampling, you need to install imbalanced-learn\n",
    "# and use the Pipeline from imblearn\n",
    "# %pip install imblearn\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13fb1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_transformer = FunctionTransformer(\n",
    "    func=pairs_to_features,\n",
    "    validate=False,\n",
    "    # Optional arguments for pairs_to_features\n",
    "    # example: kw_args={'k': 4, 'pseaac_kwargs': {'lambda_value': 30}}\n",
    "    kw_args={},\n",
    ")\n",
    "\n",
    "selector = SelectFromModel(\n",
    "    estimator=RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=9,\n",
    "        random_state=None,\n",
    "    ),\n",
    "    threshold=\"mean\",\n",
    ")\n",
    "\n",
    "# Define the classifier\n",
    "net = NeuralNetBinaryClassifier(\n",
    "    module=AptaNetMLP,\n",
    "    module__input_dim=None,\n",
    "    module__hidden_dim=128,\n",
    "    module__n_hidden=7,\n",
    "    module__dropout=0.3,\n",
    "    module__output_dim=1,\n",
    "    module__use_lazy=True,\n",
    "    criterion=torch.nn.BCEWithLogitsLoss,\n",
    "    max_epochs=200,\n",
    "    lr=0.00014,\n",
    "    optimizer=torch.optim.RMSprop,\n",
    "    optimizer__alpha=0.9,\n",
    "    optimizer__eps=1e-08,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"features\", feature_transformer),\n",
    "        # Optional under-sampling, use sklearn's Pipeline if you do not need it\n",
    "        (\"ncr\", NeighbourhoodCleaningRule()),\n",
    "        (\"selector\", selector),\n",
    "        (\"clf\", net),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ed76399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6273\u001b[0m       \u001b[32m0.7143\u001b[0m        \u001b[35m0.6764\u001b[0m  0.0100\n",
      "      2        0.7735       0.7143        \u001b[35m0.6757\u001b[0m  0.0100\n",
      "      3        0.6896       0.7143        \u001b[35m0.6753\u001b[0m  0.0115\n",
      "      4        0.6735       0.7143        \u001b[35m0.6749\u001b[0m  0.0090\n",
      "      5        0.6711       0.7143        \u001b[35m0.6746\u001b[0m  0.0100\n",
      "      6        0.7274       0.7143        \u001b[35m0.6742\u001b[0m  0.0090\n",
      "      7        0.7224       0.7143        \u001b[35m0.6739\u001b[0m  0.0100\n",
      "      8        0.6979       0.7143        \u001b[35m0.6737\u001b[0m  0.0100\n",
      "      9        0.7152       0.7143        \u001b[35m0.6735\u001b[0m  0.0100\n",
      "     10        0.6345       0.7143        \u001b[35m0.6732\u001b[0m  0.0099\n",
      "     11        0.6387       0.7143        \u001b[35m0.6729\u001b[0m  0.0100\n",
      "     12        \u001b[36m0.6151\u001b[0m       0.7143        \u001b[35m0.6726\u001b[0m  0.0091\n",
      "     13        0.6275       0.7143        \u001b[35m0.6724\u001b[0m  0.0100\n",
      "     14        \u001b[36m0.5243\u001b[0m       0.7143        \u001b[35m0.6722\u001b[0m  0.0090\n",
      "     15        0.6746       0.7143        \u001b[35m0.6719\u001b[0m  0.0090\n",
      "     16        0.6898       0.7143        \u001b[35m0.6717\u001b[0m  0.0110\n",
      "     17        0.6723       0.7143        \u001b[35m0.6715\u001b[0m  0.0090\n",
      "     18        0.6379       0.7143        \u001b[35m0.6713\u001b[0m  0.0090\n",
      "     19        0.6670       0.7143        \u001b[35m0.6710\u001b[0m  0.0100\n",
      "     20        0.5744       0.7143        \u001b[35m0.6708\u001b[0m  0.0105\n",
      "     21        0.5858       0.7143        \u001b[35m0.6706\u001b[0m  0.0090\n",
      "     22        0.6417       0.7143        \u001b[35m0.6704\u001b[0m  0.0090\n",
      "     23        0.6178       0.7143        \u001b[35m0.6702\u001b[0m  0.0100\n",
      "     24        0.6948       0.7143        \u001b[35m0.6700\u001b[0m  0.0100\n",
      "     25        0.6182       0.7143        \u001b[35m0.6698\u001b[0m  0.0090\n",
      "     26        0.6296       0.7143        \u001b[35m0.6695\u001b[0m  0.0090\n",
      "     27        0.6595       0.7143        \u001b[35m0.6693\u001b[0m  0.0090\n",
      "     28        0.6664       0.7143        \u001b[35m0.6691\u001b[0m  0.0090\n",
      "     29        0.6273       0.7143        \u001b[35m0.6689\u001b[0m  0.0095\n",
      "     30        0.7023       0.7143        \u001b[35m0.6686\u001b[0m  0.0090\n",
      "     31        0.6944       0.7143        \u001b[35m0.6685\u001b[0m  0.0090\n",
      "     32        0.6995       0.7143        \u001b[35m0.6683\u001b[0m  0.0090\n",
      "     33        0.6851       0.7143        \u001b[35m0.6681\u001b[0m  0.0090\n",
      "     34        0.7116       0.7143        \u001b[35m0.6679\u001b[0m  0.0100\n",
      "     35        0.6649       0.7143        \u001b[35m0.6676\u001b[0m  0.0080\n",
      "     36        0.6810       0.7143        \u001b[35m0.6674\u001b[0m  0.0100\n",
      "     37        0.5927       0.7143        \u001b[35m0.6672\u001b[0m  0.0095\n",
      "     38        0.6139       0.7143        \u001b[35m0.6670\u001b[0m  0.0090\n",
      "     39        0.6564       0.7143        \u001b[35m0.6668\u001b[0m  0.0080\n",
      "     40        0.6074       0.7143        \u001b[35m0.6666\u001b[0m  0.0090\n",
      "     41        0.6092       0.7143        \u001b[35m0.6664\u001b[0m  0.0080\n",
      "     42        0.6170       0.7143        \u001b[35m0.6662\u001b[0m  0.0090\n",
      "     43        0.6503       0.7143        \u001b[35m0.6660\u001b[0m  0.0090\n",
      "     44        0.6340       0.7143        \u001b[35m0.6659\u001b[0m  0.0090\n",
      "     45        0.6399       0.7143        \u001b[35m0.6657\u001b[0m  0.0070\n",
      "     46        0.6570       0.7143        \u001b[35m0.6655\u001b[0m  0.0080\n",
      "     47        0.5829       0.7143        \u001b[35m0.6652\u001b[0m  0.0085\n",
      "     48        0.6202       0.7143        \u001b[35m0.6650\u001b[0m  0.0080\n",
      "     49        0.6489       0.7143        \u001b[35m0.6648\u001b[0m  0.0080\n",
      "     50        0.6484       0.7143        \u001b[35m0.6647\u001b[0m  0.0080\n",
      "     51        0.6643       0.7143        \u001b[35m0.6644\u001b[0m  0.0080\n",
      "     52        0.6557       0.7143        \u001b[35m0.6642\u001b[0m  0.0080\n",
      "     53        0.6947       0.7143        \u001b[35m0.6640\u001b[0m  0.0070\n",
      "     54        0.6883       0.7143        \u001b[35m0.6638\u001b[0m  0.0070\n",
      "     55        0.6595       0.7143        \u001b[35m0.6636\u001b[0m  0.0090\n",
      "     56        0.6443       0.7143        \u001b[35m0.6634\u001b[0m  0.0080\n",
      "     57        0.6353       0.7143        \u001b[35m0.6633\u001b[0m  0.0081\n",
      "     58        0.5882       0.7143        \u001b[35m0.6631\u001b[0m  0.0070\n",
      "     59        0.6936       0.7143        \u001b[35m0.6630\u001b[0m  0.0080\n",
      "     60        0.6172       0.7143        \u001b[35m0.6627\u001b[0m  0.0090\n",
      "     61        0.6108       0.7143        \u001b[35m0.6625\u001b[0m  0.0070\n",
      "     62        0.6961       0.7143        \u001b[35m0.6624\u001b[0m  0.0080\n",
      "     63        0.6329       0.7143        \u001b[35m0.6621\u001b[0m  0.0080\n",
      "     64        0.6637       0.7143        \u001b[35m0.6620\u001b[0m  0.0070\n",
      "     65        0.6806       0.7143        \u001b[35m0.6618\u001b[0m  0.0070\n",
      "     66        0.6154       0.7143        \u001b[35m0.6616\u001b[0m  0.0080\n",
      "     67        0.5931       0.7143        \u001b[35m0.6614\u001b[0m  0.0080\n",
      "     68        0.6677       0.7143        \u001b[35m0.6612\u001b[0m  0.0080\n",
      "     69        0.5919       0.7143        \u001b[35m0.6609\u001b[0m  0.0070\n",
      "     70        0.7100       0.7143        \u001b[35m0.6607\u001b[0m  0.0070\n",
      "     71        0.6866       0.7143        \u001b[35m0.6605\u001b[0m  0.0080\n",
      "     72        0.6105       0.7143        \u001b[35m0.6603\u001b[0m  0.0080\n",
      "     73        0.6387       0.7143        \u001b[35m0.6601\u001b[0m  0.0080\n",
      "     74        0.6274       0.7143        \u001b[35m0.6599\u001b[0m  0.0080\n",
      "     75        0.6793       0.7143        \u001b[35m0.6596\u001b[0m  0.0080\n",
      "     76        0.6252       0.7143        \u001b[35m0.6594\u001b[0m  0.0080\n",
      "     77        0.6543       0.7143        \u001b[35m0.6592\u001b[0m  0.0070\n",
      "     78        0.6728       0.7143        \u001b[35m0.6590\u001b[0m  0.0081\n",
      "     79        0.5943       0.7143        \u001b[35m0.6588\u001b[0m  0.0070\n",
      "     80        0.7353       0.7143        \u001b[35m0.6586\u001b[0m  0.0080\n",
      "     81        0.5809       0.7143        \u001b[35m0.6584\u001b[0m  0.0080\n",
      "     82        0.6159       0.7143        \u001b[35m0.6582\u001b[0m  0.0070\n",
      "     83        0.7007       0.7143        \u001b[35m0.6580\u001b[0m  0.0080\n",
      "     84        0.6727       0.7143        \u001b[35m0.6578\u001b[0m  0.0080\n",
      "     85        0.6907       0.7143        \u001b[35m0.6577\u001b[0m  0.0070\n",
      "     86        0.6314       0.7143        \u001b[35m0.6575\u001b[0m  0.0090\n",
      "     87        0.5334       0.7143        \u001b[35m0.6573\u001b[0m  0.0090\n",
      "     88        0.6175       0.7143        \u001b[35m0.6571\u001b[0m  0.0080\n",
      "     89        0.5901       0.7143        \u001b[35m0.6569\u001b[0m  0.0080\n",
      "     90        0.5466       0.7143        \u001b[35m0.6567\u001b[0m  0.0080\n",
      "     91        0.5338       0.7143        \u001b[35m0.6564\u001b[0m  0.0070\n",
      "     92        0.5889       0.7143        \u001b[35m0.6562\u001b[0m  0.0070\n",
      "     93        0.6772       0.7143        \u001b[35m0.6559\u001b[0m  0.0080\n",
      "     94        0.5663       0.7143        \u001b[35m0.6557\u001b[0m  0.0080\n",
      "     95        0.5575       0.7143        \u001b[35m0.6555\u001b[0m  0.0070\n",
      "     96        0.6133       0.7143        \u001b[35m0.6553\u001b[0m  0.0080\n",
      "     97        0.6660       0.7143        \u001b[35m0.6551\u001b[0m  0.0080\n",
      "     98        0.5870       0.7143        \u001b[35m0.6549\u001b[0m  0.0090\n",
      "     99        0.6954       0.7143        \u001b[35m0.6548\u001b[0m  0.0080\n",
      "    100        0.5937       0.7143        \u001b[35m0.6546\u001b[0m  0.0080\n",
      "    101        0.6137       0.7143        \u001b[35m0.6543\u001b[0m  0.0080\n",
      "    102        0.6273       0.7143        \u001b[35m0.6541\u001b[0m  0.0080\n",
      "    103        0.6436       0.7143        \u001b[35m0.6539\u001b[0m  0.0080\n",
      "    104        0.6746       0.7143        \u001b[35m0.6536\u001b[0m  0.0080\n",
      "    105        0.6074       0.7143        \u001b[35m0.6534\u001b[0m  0.0080\n",
      "    106        0.7244       0.7143        \u001b[35m0.6532\u001b[0m  0.0080\n",
      "    107        0.5556       0.7143        \u001b[35m0.6529\u001b[0m  0.0090\n",
      "    108        0.6032       0.7143        \u001b[35m0.6528\u001b[0m  0.0090\n",
      "    109        0.6817       0.7143        \u001b[35m0.6526\u001b[0m  0.0075\n",
      "    110        0.6894       0.7143        \u001b[35m0.6524\u001b[0m  0.0080\n",
      "    111        0.6672       0.7143        \u001b[35m0.6522\u001b[0m  0.0080\n",
      "    112        0.5857       0.7143        \u001b[35m0.6519\u001b[0m  0.0090\n",
      "    113        0.5888       0.7143        \u001b[35m0.6518\u001b[0m  0.0070\n",
      "    114        0.5643       0.7143        \u001b[35m0.6515\u001b[0m  0.0080\n",
      "    115        0.6887       0.7143        \u001b[35m0.6513\u001b[0m  0.0080\n",
      "    116        0.6535       0.7143        \u001b[35m0.6511\u001b[0m  0.0090\n",
      "    117        0.5695       0.7143        \u001b[35m0.6509\u001b[0m  0.0080\n",
      "    118        0.6538       0.7143        \u001b[35m0.6507\u001b[0m  0.0090\n",
      "    119        0.6109       0.7143        \u001b[35m0.6505\u001b[0m  0.0075\n",
      "    120        0.5770       0.7143        \u001b[35m0.6503\u001b[0m  0.0090\n",
      "    121        0.6374       0.7143        \u001b[35m0.6501\u001b[0m  0.0080\n",
      "    122        0.6050       0.7143        \u001b[35m0.6499\u001b[0m  0.0080\n",
      "    123        0.6207       0.7143        \u001b[35m0.6497\u001b[0m  0.0080\n",
      "    124        0.6160       0.7143        \u001b[35m0.6495\u001b[0m  0.0080\n",
      "    125        0.5883       0.7143        \u001b[35m0.6492\u001b[0m  0.0080\n",
      "    126        0.5939       0.7143        \u001b[35m0.6489\u001b[0m  0.0080\n",
      "    127        0.6542       0.7143        \u001b[35m0.6488\u001b[0m  0.0090\n",
      "    128        0.6164       0.7143        \u001b[35m0.6485\u001b[0m  0.0090\n",
      "    129        0.6205       0.7143        \u001b[35m0.6483\u001b[0m  0.0085\n",
      "    130        0.6575       0.7143        \u001b[35m0.6481\u001b[0m  0.0080\n",
      "    131        0.6046       0.7143        \u001b[35m0.6480\u001b[0m  0.0080\n",
      "    132        0.5718       0.7143        \u001b[35m0.6477\u001b[0m  0.0070\n",
      "    133        0.6547       0.7143        \u001b[35m0.6474\u001b[0m  0.0080\n",
      "    134        0.6171       0.7143        \u001b[35m0.6472\u001b[0m  0.0080\n",
      "    135        0.6256       0.7143        \u001b[35m0.6470\u001b[0m  0.0080\n",
      "    136        0.6049       0.7143        \u001b[35m0.6468\u001b[0m  0.0080\n",
      "    137        0.5453       0.7143        \u001b[35m0.6465\u001b[0m  0.0070\n",
      "    138        0.6406       0.7143        \u001b[35m0.6464\u001b[0m  0.0080\n",
      "    139        0.6195       0.7143        \u001b[35m0.6462\u001b[0m  0.0065\n",
      "    140        0.5873       0.7143        \u001b[35m0.6460\u001b[0m  0.0070\n",
      "    141        0.6731       0.7143        \u001b[35m0.6457\u001b[0m  0.0080\n",
      "    142        0.6419       0.7143        \u001b[35m0.6455\u001b[0m  0.0080\n",
      "    143        0.6125       0.7143        \u001b[35m0.6453\u001b[0m  0.0080\n",
      "    144        0.6619       0.7143        \u001b[35m0.6451\u001b[0m  0.0090\n",
      "    145        0.7635       0.7143        \u001b[35m0.6448\u001b[0m  0.0080\n",
      "    146        0.6822       0.7143        \u001b[35m0.6445\u001b[0m  0.0070\n",
      "    147        0.6571       0.7143        \u001b[35m0.6443\u001b[0m  0.0080\n",
      "    148        0.6706       0.7143        \u001b[35m0.6441\u001b[0m  0.0080\n",
      "    149        0.6452       0.7143        \u001b[35m0.6439\u001b[0m  0.0090\n",
      "    150        0.6637       0.7143        \u001b[35m0.6437\u001b[0m  0.0080\n",
      "    151        0.6756       0.7143        \u001b[35m0.6435\u001b[0m  0.0090\n",
      "    152        0.6146       0.7143        \u001b[35m0.6432\u001b[0m  0.0070\n",
      "    153        0.6445       0.7143        \u001b[35m0.6430\u001b[0m  0.0070\n",
      "    154        0.6538       0.7143        \u001b[35m0.6428\u001b[0m  0.0090\n",
      "    155        0.5767       0.7143        \u001b[35m0.6426\u001b[0m  0.0080\n",
      "    156        0.5513       0.7143        \u001b[35m0.6423\u001b[0m  0.0090\n",
      "    157        0.5766       0.7143        \u001b[35m0.6421\u001b[0m  0.0080\n",
      "    158        0.5450       0.7143        \u001b[35m0.6418\u001b[0m  0.0070\n",
      "    159        0.6143       0.7143        \u001b[35m0.6416\u001b[0m  0.0080\n",
      "    160        0.5494       0.7143        \u001b[35m0.6414\u001b[0m  0.0082\n",
      "    161        0.5620       0.7143        \u001b[35m0.6413\u001b[0m  0.0070\n",
      "    162        0.5426       0.7143        \u001b[35m0.6410\u001b[0m  0.0080\n",
      "    163        0.6964       0.7143        \u001b[35m0.6408\u001b[0m  0.0080\n",
      "    164        0.6272       0.7143        \u001b[35m0.6405\u001b[0m  0.0070\n",
      "    165        \u001b[36m0.5128\u001b[0m       0.7143        \u001b[35m0.6402\u001b[0m  0.0080\n",
      "    166        0.6864       0.7143        \u001b[35m0.6399\u001b[0m  0.0090\n",
      "    167        0.5687       0.7143        \u001b[35m0.6396\u001b[0m  0.0070\n",
      "    168        0.6429       0.7143        \u001b[35m0.6394\u001b[0m  0.0090\n",
      "    169        0.6827       0.7143        \u001b[35m0.6391\u001b[0m  0.0100\n",
      "    170        0.6073       0.7143        \u001b[35m0.6389\u001b[0m  0.0075\n",
      "    171        0.5979       0.7143        \u001b[35m0.6387\u001b[0m  0.0070\n",
      "    172        0.5955       0.7143        \u001b[35m0.6385\u001b[0m  0.0080\n",
      "    173        0.6011       0.7143        \u001b[35m0.6382\u001b[0m  0.0070\n",
      "    174        0.6360       0.7143        \u001b[35m0.6381\u001b[0m  0.0080\n",
      "    175        0.5359       0.7143        \u001b[35m0.6378\u001b[0m  0.0070\n",
      "    176        0.6292       0.7143        \u001b[35m0.6375\u001b[0m  0.0090\n",
      "    177        0.6433       0.7143        \u001b[35m0.6372\u001b[0m  0.0070\n",
      "    178        0.6092       0.7143        \u001b[35m0.6370\u001b[0m  0.0080\n",
      "    179        0.6384       0.7143        \u001b[35m0.6367\u001b[0m  0.0100\n",
      "    180        0.6378       0.7143        \u001b[35m0.6365\u001b[0m  0.0065\n",
      "    181        0.6473       0.7143        \u001b[35m0.6363\u001b[0m  0.0090\n",
      "    182        0.5456       0.7143        \u001b[35m0.6360\u001b[0m  0.0080\n",
      "    183        0.5995       0.7143        \u001b[35m0.6357\u001b[0m  0.0080\n",
      "    184        0.6059       0.7143        \u001b[35m0.6354\u001b[0m  0.0080\n",
      "    185        0.5271       0.7143        \u001b[35m0.6351\u001b[0m  0.0070\n",
      "    186        0.6176       0.7143        \u001b[35m0.6349\u001b[0m  0.0080\n",
      "    187        0.6448       0.7143        \u001b[35m0.6346\u001b[0m  0.0080\n",
      "    188        \u001b[36m0.5124\u001b[0m       0.7143        \u001b[35m0.6344\u001b[0m  0.0080\n",
      "    189        0.6555       0.7143        \u001b[35m0.6343\u001b[0m  0.0080\n",
      "    190        0.6072       0.7143        \u001b[35m0.6341\u001b[0m  0.0080\n",
      "    191        0.6013       0.7143        \u001b[35m0.6338\u001b[0m  0.0080\n",
      "    192        0.5678       0.7143        \u001b[35m0.6336\u001b[0m  0.0080\n",
      "    193        0.5857       0.7143        \u001b[35m0.6333\u001b[0m  0.0080\n",
      "    194        0.6936       0.7143        \u001b[35m0.6332\u001b[0m  0.0080\n",
      "    195        0.5817       0.7143        \u001b[35m0.6330\u001b[0m  0.0090\n",
      "    196        0.5939       0.7143        \u001b[35m0.6327\u001b[0m  0.0080\n",
      "    197        0.5977       0.7143        \u001b[35m0.6325\u001b[0m  0.0070\n",
      "    198        0.6017       0.7143        \u001b[35m0.6324\u001b[0m  0.0090\n",
      "    199        0.6248       0.7143        \u001b[35m0.6321\u001b[0m  0.0080\n",
      "    200        0.5666       0.7143        \u001b[35m0.6319\u001b[0m  0.0080\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the aptamer-protein pairs\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "945dc876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.48\n"
     ]
    }
   ],
   "source": [
    "# Optional: Evaluate training accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyaptamer-latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
