{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e8d179",
   "metadata": {},
   "source": [
    "# Binding prediction using AptaNet\n",
    "Step-by-step guide for using AptaNet for binary aptamerâ€“protein binding prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a64683",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook showcases the AptaNet algorithm, a deep learning method that combines sequence-derived (k-mer + PSeAAC) features with RandomForest-based feature selection, and a multi-layer perceptron to predict whether an aptamer and a protein interact (binary classification: aptamer binds/does not bind with the target protein). An overview of the classes and helper functions used in this notebook:\n",
    "\n",
    "- **pairs_to_features**: helper that converts `(aptamer_sequence, protein_sequence)` pairs into feature vectors using k-mer + PSeAAC.\n",
    "- **SkorchAptaNet**: a PyTorch MLP wrapped in Skorch for binary classification.\n",
    "- **load_1gnh**: helper to load the 1GNH molecule structure from PDB file into our in-memory `MoleculeLoader` format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c592d9",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "To train the `AptaNetMLP` the notebook uses:\n",
    "* For `X`:\n",
    "    * 5 random aptamer sequences of length>30 (to satisfy the default lambda value of 30 set in the PSeAAC algorithm).\n",
    "    * Amino acid sequences extracted from the 1GNH protein molecule.\n",
    "    \n",
    "    The aptamer sequences and the amino acid sequences form tuples `(aptamer_sequence, protein_sequence)` to form `X`.\n",
    "* For `y`:\n",
    "    * A random binary value (to indicate if the aptamer binds or not) as dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3737da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data imports\n",
    "import torch\n",
    "\n",
    "from pyaptamer.datasets import load_1gnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2f6701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_sequence = [\n",
    "    \"GGGAGGACGAAGACGACUCGAGACAGGCUAGGGAGGGA\",\n",
    "    \"AAGCGUCGGAUCUACACGUGCGAUAGCUCAGUACGCGGU\",\n",
    "    \"CGGUAUCGAGUACAGGAGUCCGACGGAUAGUCCGGAGC\",\n",
    "    \"UAGCUAGCGAACUAGGCGUAGCUUCGAGUAGCUACGGAA\",\n",
    "    \"GCUAGGACGAUCGCACGUGACCGUCAGUAGCGUAGGAGA\",\n",
    "]\n",
    "\n",
    "gnh = load_1gnh()\n",
    "protein_sequence = gnh.to_df_seq()[\"sequence\"].tolist()\n",
    "\n",
    "# Build all combinations (aptamer, protein), duplicated to increase dataset size\n",
    "X = [(a, p) for a in aptamer_sequence for p in protein_sequence] * 5\n",
    "\n",
    "# Dummy binary labels for the pairs\n",
    "y = torch.randint(0, 2, (len(X),), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ae4ea",
   "metadata": {},
   "source": [
    "## Building the pipeline\n",
    "### Dataset balancing using the Neighbourhood cleaning rule\n",
    "In the `AptaNet` paper, the authors mention using the `NeighbourhoodCleaningRule` from `imblearn` in order to balance the dataset, as in their dataset they had more negative (0) values than positives (1).\n",
    "\n",
    " To build a scikit-learn pipeline, follow these steps:\n",
    "1. Convert the input to the desired (aptamer_sequence, protein_sequence) format.\n",
    "    * OPTIONAL: As mentioned in the paper, perform under-sampling using the  \n",
    "    Neighborhood Cleaning Rule to balance the classes.\n",
    "2. Get the PSeAAC feature vectors for your converted input (using `pairs_to_features`).\n",
    "3. Select the number of features to use from the feature vector (using `RandomForestClassifier`).\n",
    "4. Define the skorch neural network (using `AptaNetMLP`).\n",
    "### Different workflows\n",
    "In this first half of the notebook we will cover 3 different workflows one can follow, in ascending order of customizability:\n",
    "\n",
    "1. A minimal workflow with no dataset balancing, while using the in-built pipeline.\n",
    "2. Using your own custom pipeline.\n",
    "3. Dataset balancing, while using your own pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c1997",
   "metadata": {},
   "source": [
    "### First workflow\n",
    "A minimal workflow with no dataset balancing, while using the in-built pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44cc1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use the AptaNet pipeline, you can import it directly\n",
    "from pyaptamer.aptanet import AptaNetPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d782bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AptaNetPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8a0d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline on the aptamer-protein pairs\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae896e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "# Optional: Evaluate training accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a04f9",
   "metadata": {},
   "source": [
    "### Second Worflow\n",
    "\n",
    "Your own custom-built pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6130027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to build your own aptamer pipeline, you should use the following imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "\n",
    "from pyaptamer.aptanet._aptanet_nn import AptaNetMLP\n",
    "from pyaptamer.utils._aptanet_utils import pairs_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a2e277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_transformer = FunctionTransformer(\n",
    "    func=pairs_to_features,\n",
    "    validate=False,\n",
    "    # Optional arguments for pairs_to_features\n",
    "    # example: kw_args={'k': 4, 'pseaac_kwargs': {'lambda_value': 30}}\n",
    "    kw_args={},\n",
    ")\n",
    "\n",
    "selector = SelectFromModel(\n",
    "    estimator=RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=9,\n",
    "        random_state=None,\n",
    "    ),\n",
    "    threshold=\"mean\",\n",
    ")\n",
    "\n",
    "# Define the classifier\n",
    "net = NeuralNetBinaryClassifier(\n",
    "    module=AptaNetMLP,\n",
    "    module__input_dim=None,\n",
    "    module__hidden_dim=128,\n",
    "    module__n_hidden=7,\n",
    "    module__dropout=0.3,\n",
    "    module__output_dim=1,\n",
    "    module__use_lazy=True,\n",
    "    criterion=torch.nn.BCEWithLogitsLoss,\n",
    "    max_epochs=200,\n",
    "    lr=0.00014,\n",
    "    optimizer=torch.optim.RMSprop,\n",
    "    optimizer__alpha=0.9,\n",
    "    optimizer__eps=1e-08,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"features\", feature_transformer),\n",
    "        (\"selector\", selector),\n",
    "        (\"clf\", net),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8049a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7350\u001b[0m       \u001b[32m0.4000\u001b[0m        \u001b[35m0.6969\u001b[0m  0.0233\n",
      "      2        \u001b[36m0.7155\u001b[0m       0.4000        0.6970  0.0076\n",
      "      3        0.7476       0.4000        0.6970  0.0097\n",
      "      4        0.7367       0.4000        0.6969  0.0096\n",
      "      5        0.7433       0.4000        \u001b[35m0.6968\u001b[0m  0.0079\n",
      "      6        \u001b[36m0.7119\u001b[0m       0.4000        \u001b[35m0.6968\u001b[0m  0.0085\n",
      "      7        \u001b[36m0.7063\u001b[0m       0.4000        \u001b[35m0.6967\u001b[0m  0.0080\n",
      "      8        \u001b[36m0.6887\u001b[0m       0.4000        \u001b[35m0.6967\u001b[0m  0.0061\n",
      "      9        0.8330       0.4000        \u001b[35m0.6966\u001b[0m  0.0117\n",
      "     10        0.6932       0.4000        \u001b[35m0.6966\u001b[0m  0.0077\n",
      "     11        0.7472       0.4000        \u001b[35m0.6966\u001b[0m  0.0070\n",
      "     12        \u001b[36m0.6552\u001b[0m       0.4000        \u001b[35m0.6965\u001b[0m  0.0078\n",
      "     13        0.7338       0.4000        0.6965  0.0066\n",
      "     14        0.7274       0.4000        \u001b[35m0.6964\u001b[0m  0.0070\n",
      "     15        0.6904       0.4000        \u001b[35m0.6964\u001b[0m  0.0093\n",
      "     16        \u001b[36m0.6215\u001b[0m       0.4000        \u001b[35m0.6964\u001b[0m  0.0083\n",
      "     17        0.7753       0.4000        \u001b[35m0.6964\u001b[0m  0.0080\n",
      "     18        0.6804       0.4000        \u001b[35m0.6963\u001b[0m  0.0090\n",
      "     19        0.7450       0.4000        \u001b[35m0.6962\u001b[0m  0.0071\n",
      "     20        0.7210       0.4000        \u001b[35m0.6962\u001b[0m  0.0080\n",
      "     21        0.7592       0.4000        \u001b[35m0.6961\u001b[0m  0.0097\n",
      "     22        0.6527       0.4000        \u001b[35m0.6961\u001b[0m  0.0070\n",
      "     23        0.7486       0.4000        \u001b[35m0.6960\u001b[0m  0.0077\n",
      "     24        0.8704       0.4000        \u001b[35m0.6960\u001b[0m  0.0060\n",
      "     25        0.6613       0.4000        \u001b[35m0.6959\u001b[0m  0.0120\n",
      "     26        0.7517       0.4000        \u001b[35m0.6959\u001b[0m  0.0100\n",
      "     27        0.6323       0.4000        \u001b[35m0.6959\u001b[0m  0.0078\n",
      "     28        0.7216       0.4000        0.6959  0.0086\n",
      "     29        0.6791       0.4000        \u001b[35m0.6959\u001b[0m  0.0066\n",
      "     30        0.7074       0.4000        \u001b[35m0.6958\u001b[0m  0.0085\n",
      "     31        0.6925       0.4000        0.6959  0.0093\n",
      "     32        0.7016       0.4000        0.6959  0.0065\n",
      "     33        0.7076       0.4000        0.6958  0.0081\n",
      "     34        0.6570       0.4000        \u001b[35m0.6958\u001b[0m  0.0086\n",
      "     35        0.7341       0.4000        \u001b[35m0.6958\u001b[0m  0.0093\n",
      "     36        0.7137       0.4000        \u001b[35m0.6958\u001b[0m  0.0080\n",
      "     37        0.7607       0.4000        0.6958  0.0117\n",
      "     38        0.7060       0.4000        \u001b[35m0.6957\u001b[0m  0.0081\n",
      "     39        0.7082       0.4000        \u001b[35m0.6957\u001b[0m  0.0082\n",
      "     40        0.8125       0.4000        \u001b[35m0.6957\u001b[0m  0.0090\n",
      "     41        0.7520       0.4000        \u001b[35m0.6956\u001b[0m  0.0076\n",
      "     42        0.6657       0.4000        \u001b[35m0.6956\u001b[0m  0.0100\n",
      "     43        0.7409       0.4000        \u001b[35m0.6955\u001b[0m  0.0075\n",
      "     44        0.7180       0.4000        \u001b[35m0.6955\u001b[0m  0.0065\n",
      "     45        0.7337       0.4000        \u001b[35m0.6955\u001b[0m  0.0085\n",
      "     46        0.7352       0.4000        \u001b[35m0.6955\u001b[0m  0.0060\n",
      "     47        0.7124       0.4000        \u001b[35m0.6955\u001b[0m  0.0085\n",
      "     48        0.7103       0.4000        \u001b[35m0.6955\u001b[0m  0.0085\n",
      "     49        0.7436       0.4000        \u001b[35m0.6955\u001b[0m  0.0100\n",
      "     50        0.7158       0.4000        0.6955  0.0080\n",
      "     51        0.6836       0.4000        \u001b[35m0.6954\u001b[0m  0.0088\n",
      "     52        0.7067       0.4000        \u001b[35m0.6954\u001b[0m  0.0070\n",
      "     53        0.8126       0.4000        \u001b[35m0.6953\u001b[0m  0.0071\n",
      "     54        0.7505       0.4000        \u001b[35m0.6953\u001b[0m  0.0080\n",
      "     55        0.7035       0.4000        \u001b[35m0.6953\u001b[0m  0.0089\n",
      "     56        0.6918       0.4000        \u001b[35m0.6953\u001b[0m  0.0100\n",
      "     57        0.6607       0.4000        \u001b[35m0.6953\u001b[0m  0.0088\n",
      "     58        0.7366       0.4000        0.6953  0.0080\n",
      "     59        0.6874       0.4000        \u001b[35m0.6952\u001b[0m  0.0057\n",
      "     60        0.7360       0.4000        \u001b[35m0.6952\u001b[0m  0.0076\n",
      "     61        0.7753       0.4000        \u001b[35m0.6952\u001b[0m  0.0098\n",
      "     62        0.6481       0.4000        \u001b[35m0.6951\u001b[0m  0.0065\n",
      "     63        0.7290       0.4000        \u001b[35m0.6951\u001b[0m  0.0089\n",
      "     64        0.8687       0.4000        0.6951  0.0092\n",
      "     65        0.7170       0.4000        0.6951  0.0061\n",
      "     66        0.8065       0.4000        \u001b[35m0.6951\u001b[0m  0.0092\n",
      "     67        0.6700       0.4000        \u001b[35m0.6951\u001b[0m  0.0103\n",
      "     68        0.7126       0.4000        \u001b[35m0.6950\u001b[0m  0.0070\n",
      "     69        0.7610       0.4000        \u001b[35m0.6950\u001b[0m  0.0095\n",
      "     70        0.8078       0.4000        \u001b[35m0.6950\u001b[0m  0.0076\n",
      "     71        0.6517       0.4000        \u001b[35m0.6949\u001b[0m  0.0087\n",
      "     72        0.7218       0.4000        \u001b[35m0.6949\u001b[0m  0.0110\n",
      "     73        0.7739       0.4000        \u001b[35m0.6948\u001b[0m  0.0073\n",
      "     74        0.6724       0.4000        \u001b[35m0.6948\u001b[0m  0.0070\n",
      "     75        0.7922       0.4000        \u001b[35m0.6947\u001b[0m  0.0097\n",
      "     76        0.7556       0.4000        \u001b[35m0.6947\u001b[0m  0.0072\n",
      "     77        0.7015       0.4000        \u001b[35m0.6947\u001b[0m  0.0079\n",
      "     78        0.7493       0.4000        \u001b[35m0.6946\u001b[0m  0.0070\n",
      "     79        0.7320       0.4000        \u001b[35m0.6945\u001b[0m  0.0075\n",
      "     80        0.7866       0.4000        \u001b[35m0.6945\u001b[0m  0.0086\n",
      "     81        0.7109       0.4000        \u001b[35m0.6945\u001b[0m  0.0085\n",
      "     82        0.6826       0.4000        \u001b[35m0.6945\u001b[0m  0.0092\n",
      "     83        0.6381       0.4000        \u001b[35m0.6944\u001b[0m  0.0085\n",
      "     84        \u001b[36m0.5972\u001b[0m       0.4000        \u001b[35m0.6944\u001b[0m  0.0061\n",
      "     85        0.6351       0.4000        \u001b[35m0.6943\u001b[0m  0.0091\n",
      "     86        0.7468       0.4000        \u001b[35m0.6943\u001b[0m  0.0061\n",
      "     87        0.6746       0.4000        \u001b[35m0.6943\u001b[0m  0.0085\n",
      "     88        0.7407       0.4000        0.6943  0.0091\n",
      "     89        0.7575       0.4000        \u001b[35m0.6943\u001b[0m  0.0060\n",
      "     90        0.7140       0.4000        \u001b[35m0.6942\u001b[0m  0.0100\n",
      "     91        0.6691       0.4000        \u001b[35m0.6942\u001b[0m  0.0075\n",
      "     92        0.7133       0.4000        0.6942  0.0102\n",
      "     93        0.7113       0.4000        0.6942  0.0090\n",
      "     94        0.7163       0.4000        \u001b[35m0.6942\u001b[0m  0.0065\n",
      "     95        0.8031       0.4000        \u001b[35m0.6942\u001b[0m  0.0086\n",
      "     96        0.6689       0.4000        \u001b[35m0.6941\u001b[0m  0.0085\n",
      "     97        0.6610       0.4000        \u001b[35m0.6941\u001b[0m  0.0065\n",
      "     98        0.6480       0.4000        \u001b[35m0.6940\u001b[0m  0.0100\n",
      "     99        0.7951       0.4000        \u001b[35m0.6940\u001b[0m  0.0055\n",
      "    100        0.7528       0.4000        \u001b[35m0.6940\u001b[0m  0.0087\n",
      "    101        0.6892       0.4000        0.6940  0.0110\n",
      "    102        0.6395       0.4000        0.6940  0.0067\n",
      "    103        0.7910       0.4000        \u001b[35m0.6940\u001b[0m  0.0079\n",
      "    104        0.6761       0.4000        \u001b[35m0.6939\u001b[0m  0.0102\n",
      "    105        0.7864       0.4000        \u001b[35m0.6939\u001b[0m  0.0060\n",
      "    106        0.6971       0.4000        \u001b[35m0.6938\u001b[0m  0.0088\n",
      "    107        0.7543       0.4000        \u001b[35m0.6938\u001b[0m  0.0080\n",
      "    108        0.7882       0.4000        \u001b[35m0.6938\u001b[0m  0.0067\n",
      "    109        0.6598       0.4000        \u001b[35m0.6938\u001b[0m  0.0100\n",
      "    110        0.7030       0.4000        0.6938  0.0055\n",
      "    111        0.7459       0.4000        0.6938  0.0082\n",
      "    112        0.7881       0.4000        \u001b[35m0.6937\u001b[0m  0.0060\n",
      "    113        0.7260       0.4000        \u001b[35m0.6937\u001b[0m  0.0075\n",
      "    114        0.7578       0.4000        0.6937  0.0100\n",
      "    115        0.7438       0.4000        \u001b[35m0.6937\u001b[0m  0.0065\n",
      "    116        0.6837       0.4000        \u001b[35m0.6936\u001b[0m  0.0080\n",
      "    117        0.6785       0.4000        \u001b[35m0.6936\u001b[0m  0.0082\n",
      "    118        0.6642       0.4000        \u001b[35m0.6935\u001b[0m  0.0070\n",
      "    119        0.6595       0.4000        \u001b[35m0.6935\u001b[0m  0.0078\n",
      "    120        0.6058       0.4000        \u001b[35m0.6935\u001b[0m  0.0088\n",
      "    121        0.7715       0.4000        \u001b[35m0.6935\u001b[0m  0.0092\n",
      "    122        0.7494       0.4000        \u001b[35m0.6935\u001b[0m  0.0070\n",
      "    123        0.7075       0.4000        \u001b[35m0.6935\u001b[0m  0.0070\n",
      "    124        0.7276       0.4000        \u001b[35m0.6934\u001b[0m  0.0076\n",
      "    125        0.7212       0.4000        \u001b[35m0.6934\u001b[0m  0.0090\n",
      "    126        0.7056       0.4000        0.6934  0.0088\n",
      "    127        0.7507       0.4000        0.6934  0.0070\n",
      "    128        0.7287       0.4000        \u001b[35m0.6934\u001b[0m  0.0089\n",
      "    129        0.7329       0.4000        \u001b[35m0.6933\u001b[0m  0.0100\n",
      "    130        0.7344       0.4000        \u001b[35m0.6933\u001b[0m  0.0056\n",
      "    131        0.7566       0.4000        \u001b[35m0.6933\u001b[0m  0.0070\n",
      "    132        0.7145       0.4000        0.6933  0.0108\n",
      "    133        0.7027       0.4000        0.6933  0.0070\n",
      "    134        0.7753       0.4000        \u001b[35m0.6933\u001b[0m  0.0101\n",
      "    135        0.6307       0.4000        \u001b[35m0.6933\u001b[0m  0.0060\n",
      "    136        0.6800       0.4000        0.6933  0.0070\n",
      "    137        0.6693       0.4000        \u001b[35m0.6932\u001b[0m  0.0090\n",
      "    138        0.6285       0.4000        \u001b[35m0.6932\u001b[0m  0.0066\n",
      "    139        0.6168       0.4000        0.6932  0.0090\n",
      "    140        0.6697       0.4000        \u001b[35m0.6932\u001b[0m  0.0070\n",
      "    141        0.7072       0.4000        \u001b[35m0.6932\u001b[0m  0.0075\n",
      "    142        0.7790       \u001b[32m0.6000\u001b[0m        \u001b[35m0.6931\u001b[0m  0.0091\n",
      "    143        0.7670       0.6000        0.6931  0.0061\n",
      "    144        0.8322       0.6000        0.6931  0.0086\n",
      "    145        0.7330       0.4000        0.6931  0.0074\n",
      "    146        0.7955       0.6000        0.6931  0.0090\n",
      "    147        0.7266       0.6000        \u001b[35m0.6931\u001b[0m  0.0082\n",
      "    148        0.7400       0.6000        \u001b[35m0.6931\u001b[0m  0.0065\n",
      "    149        0.7811       0.6000        \u001b[35m0.6930\u001b[0m  0.0087\n",
      "    150        0.7214       0.6000        0.6930  0.0090\n",
      "    151        0.7852       0.6000        0.6930  0.0067\n",
      "    152        0.6754       0.6000        \u001b[35m0.6930\u001b[0m  0.0090\n",
      "    153        0.7142       0.6000        \u001b[35m0.6929\u001b[0m  0.0061\n",
      "    154        0.6761       0.6000        \u001b[35m0.6929\u001b[0m  0.0085\n",
      "    155        0.7725       0.6000        0.6929  0.0066\n",
      "    156        0.6741       0.6000        \u001b[35m0.6929\u001b[0m  0.0081\n",
      "    157        0.7663       0.6000        \u001b[35m0.6929\u001b[0m  0.0070\n",
      "    158        0.8139       0.6000        \u001b[35m0.6928\u001b[0m  0.0067\n",
      "    159        0.8255       0.6000        0.6928  0.0091\n",
      "    160        0.6565       0.6000        \u001b[35m0.6928\u001b[0m  0.0072\n",
      "    161        0.7320       0.6000        0.6928  0.0080\n",
      "    162        0.6928       0.6000        0.6928  0.0093\n",
      "    163        0.7028       0.6000        \u001b[35m0.6927\u001b[0m  0.0110\n",
      "    164        0.6770       0.6000        \u001b[35m0.6927\u001b[0m  0.0076\n",
      "    165        0.6207       0.6000        0.6927  0.0088\n",
      "    166        0.6371       0.6000        0.6928  0.0101\n",
      "    167        \u001b[36m0.5886\u001b[0m       0.6000        0.6927  0.0119\n",
      "    168        0.7545       0.6000        \u001b[35m0.6927\u001b[0m  0.0078\n",
      "    169        0.7270       0.6000        \u001b[35m0.6927\u001b[0m  0.0110\n",
      "    170        0.7113       0.6000        \u001b[35m0.6927\u001b[0m  0.0102\n",
      "    171        0.7064       0.6000        \u001b[35m0.6926\u001b[0m  0.0110\n",
      "    172        0.6523       0.6000        \u001b[35m0.6926\u001b[0m  0.0146\n",
      "    173        0.7466       0.6000        \u001b[35m0.6926\u001b[0m  0.0127\n",
      "    174        0.7157       0.6000        \u001b[35m0.6926\u001b[0m  0.0156\n",
      "    175        0.6410       0.6000        \u001b[35m0.6925\u001b[0m  0.0075\n",
      "    176        0.6703       0.6000        \u001b[35m0.6925\u001b[0m  0.0078\n",
      "    177        0.6925       0.6000        \u001b[35m0.6925\u001b[0m  0.0095\n",
      "    178        0.7221       0.6000        \u001b[35m0.6925\u001b[0m  0.0091\n",
      "    179        0.7750       0.6000        \u001b[35m0.6925\u001b[0m  0.0077\n",
      "    180        0.7135       0.6000        \u001b[35m0.6925\u001b[0m  0.0116\n",
      "    181        0.7199       0.6000        \u001b[35m0.6925\u001b[0m  0.0081\n",
      "    182        0.8058       0.6000        \u001b[35m0.6924\u001b[0m  0.0090\n",
      "    183        0.7156       0.6000        \u001b[35m0.6924\u001b[0m  0.0070\n",
      "    184        0.7769       0.6000        \u001b[35m0.6924\u001b[0m  0.0077\n",
      "    185        0.6374       0.6000        \u001b[35m0.6924\u001b[0m  0.0090\n",
      "    186        0.6430       0.6000        \u001b[35m0.6923\u001b[0m  0.0147\n",
      "    187        0.6916       0.6000        \u001b[35m0.6923\u001b[0m  0.0112\n",
      "    188        0.7929       0.6000        \u001b[35m0.6923\u001b[0m  0.0085\n",
      "    189        0.7356       0.6000        \u001b[35m0.6923\u001b[0m  0.0080\n",
      "    190        0.6499       0.6000        \u001b[35m0.6923\u001b[0m  0.0097\n",
      "    191        0.7136       0.6000        \u001b[35m0.6923\u001b[0m  0.0100\n",
      "    192        0.6607       0.6000        \u001b[35m0.6922\u001b[0m  0.0080\n",
      "    193        0.7427       0.6000        \u001b[35m0.6922\u001b[0m  0.0110\n",
      "    194        0.7636       0.6000        \u001b[35m0.6922\u001b[0m  0.0090\n",
      "    195        0.7364       0.6000        0.6922  0.0070\n",
      "    196        0.7112       0.6000        \u001b[35m0.6922\u001b[0m  0.0088\n",
      "    197        0.7580       0.6000        \u001b[35m0.6922\u001b[0m  0.0116\n",
      "    198        0.6929       0.6000        \u001b[35m0.6921\u001b[0m  0.0070\n",
      "    199        0.7500       0.6000        \u001b[35m0.6921\u001b[0m  0.0091\n",
      "    200        0.6934       0.6000        \u001b[35m0.6921\u001b[0m  0.0070\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the aptamer-protein pairs\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f00091db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "# Optional: Evaluate training accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db693e",
   "metadata": {},
   "source": [
    "### Third workflow\n",
    "Dataset balancing using under-sampling, while using your own pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "523f4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to build your own aptamer pipeline, you should use the following imports\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from pyaptamer.aptanet import AptaNetClassifier, AptaNetPipeline\n",
    "from pyaptamer.utils._aptanet_utils import pairs_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0cf0bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: If you want to use the Neighborhood Cleaning Rule for under-sampling\n",
    "# NOTE: If you want to use under-sampling, you need to install imbalanced-learn\n",
    "# and use the Pipeline from imblearn\n",
    "# %pip install imblearn\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13fb1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_transformer = FunctionTransformer(\n",
    "    func=pairs_to_features,\n",
    "    validate=False,\n",
    "    # Optional arguments for pairs_to_features\n",
    "    # example: kw_args={'k': 4, 'pseaac_kwargs': {'lambda_value': 30}}\n",
    "    kw_args={},\n",
    ")\n",
    "\n",
    "# AptaNetClassifier encapsulates the \"selector\" and \"net\" mentioned in Workflow 2\n",
    "clf = AptaNetClassifier()\n",
    "\n",
    "model = Pipeline(\n",
    "    [\n",
    "        (\"ncr\", NeighbourhoodCleaningRule()),\n",
    "        (\"clf\", clf),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = AptaNetPipeline(estimator=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ed76399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\satvm\\miniconda3\\envs\\pyaptamer-latest\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the aptamer-protein pairs\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "945dc876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.44\n"
     ]
    }
   ],
   "source": [
    "# Optional: Evaluate training accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0947e5d2",
   "metadata": {},
   "source": [
    "# Implementing `AptaNet` for real-world use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94894a1b",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "To train the `AptaNetMLP` the notebook uses the dataset used to train the `AptaTrans` algorithm, this dataset can be found in `pyaptamer/datasets/data/train_li2014`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e2dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data imports\n",
    "\n",
    "from pyaptamer.datasets import load_li2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_li2014(split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f1442f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aptamer</th>\n",
       "      <th>protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCGGAGGUGGUUCAGCUCUGCAUCGACAGUUGGC</td>\n",
       "      <td>MDSTNYISKLFEYAQRQGQISDIKFEEVGTDGPDHLKTFTLRVVIK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CGGGGTGTTGTCCTGTGCTCTCCGGAGAGCACAGGACAACACCCCG</td>\n",
       "      <td>MDELFPLIFPAEPAQASGPYVEIIEQPKQRGMRFRYKCEGRSAGSI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GCTGCAGTTGCACTGAATTCGCCTCTCGCCTCCGTACACTTAGTCG...</td>\n",
       "      <td>MDEVGAQVAAPMFIHQSLGRKRDLYYPMSNRLVQSQPQRRDEWNSK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TATTTGCCCTTGCAGGCCGCAGGAGTGCTAGCAGT</td>\n",
       "      <td>PISPIDTVPVKLKPGMDGPKVKQWPLTEEKIKALTEICNEMEKEGK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCUCUGGGCUCUUAGGAGAACGGAUAGGAGUGUGCUCGCU</td>\n",
       "      <td>LQENFLPQPRQQHHGTLVLHYRPHREEAGMQHPCLWPGSSHCSDDS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             aptamer  \\\n",
       "0                 UCGGAGGUGGUUCAGCUCUGCAUCGACAGUUGGC   \n",
       "1     CGGGGTGTTGTCCTGTGCTCTCCGGAGAGCACAGGACAACACCCCG   \n",
       "2  GCTGCAGTTGCACTGAATTCGCCTCTCGCCTCCGTACACTTAGTCG...   \n",
       "3                TATTTGCCCTTGCAGGCCGCAGGAGTGCTAGCAGT   \n",
       "4           UCUCUGGGCUCUUAGGAGAACGGAUAGGAGUGUGCUCGCU   \n",
       "\n",
       "                                             protein  \n",
       "0  MDSTNYISKLFEYAQRQGQISDIKFEEVGTDGPDHLKTFTLRVVIK...  \n",
       "1  MDELFPLIFPAEPAQASGPYVEIIEQPKQRGMRFRYKCEGRSAGSI...  \n",
       "2  MDEVGAQVAAPMFIHQSLGRKRDLYYPMSNRLVQSQPQRRDEWNSK...  \n",
       "3  PISPIDTVPVKLKPGMDGPKVKQWPLTEEKIKALTEICNEMEKEGK...  \n",
       "4  LQENFLPQPRQQHHGTLVLHYRPHREEAGMQHPCLWPGSSHCSDDS...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows of X which contains aptamer-protein pairs\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2a63d1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    positive\n",
       "1    positive\n",
       "2    positive\n",
       "3    positive\n",
       "4    positive\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows of y which contains binary binding labels\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01001dd2",
   "metadata": {},
   "source": [
    "## DIfferent Real-world examples\n",
    "In the second half of this notebook we will explore 3 real-world use cases of the algorithm. These include:\n",
    "1. Training on the entire AptaTrans dataset, and predict binding probability (`predict_proba`) between a protein and a DNA sequence.\n",
    "2. TODO: Same for using DNA sequences from a `fasta` file.\n",
    "3. Using MCTS combined with a trained `AptaNet` to propose new aptamers for a new pdb file, i.e., a form of in-silico Selex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71f1648e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satvm\\pyaptamer\\pyaptamer\\pseaac\\_pseaac_aptanet.py:196: UserWarning: Invalid amino acid(s) found in sequence. Replaced with 'N'.\n",
      "  seq = clean_protein_seq(protein_sequence)\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the aptamer-protein pairs from the `AptaTrans` dataset\n",
    "pipeline = AptaNetPipeline()\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94949073",
   "metadata": {},
   "source": [
    "### First workflow\n",
    "\n",
    "Predicting binding probability (`predict_proba`) between a protein (1GNH) and a DNA sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c5a42a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9614966 , 0.03850342]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aptamer_sequence = \"GGGAGGACGAAGACGACUCGAGACAGGCUAGGGAGGGA\"\n",
    "\n",
    "X = [(aptamer_sequence, p) for p in protein_sequence]\n",
    "\n",
    "pipeline.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af501b0c",
   "metadata": {},
   "source": [
    "### Second workflow (TODO)\n",
    "\n",
    "Predicting binding probability (`predict_proba`) between a protein (1GNH) and DNA sequences from a `fasta` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16420bc4",
   "metadata": {},
   "source": [
    "### Third workflow\n",
    "\n",
    "Using MCTS combined with a trained `AptaNet` to propose new aptamers for a protein (1GNH), i.e., a form of in-silico Selex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aadff246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- Round: 1 -----\n",
      "##################################################\n",
      "Best subsequence: _C_C_U\n",
      "Depth: 3\n",
      "##################################################\n",
      "\n",
      " ----- Round: 2 -----\n",
      "##################################################\n",
      "Best subsequence: _C_C_U_CA_C_\n",
      "Depth: 6\n",
      "##################################################\n",
      "\n",
      " ----- Round: 3 -----\n",
      "##################################################\n",
      "Best subsequence: _C_C_U_CA_C_C_U_A_\n",
      "Depth: 9\n",
      "##################################################\n",
      "\n",
      " ----- Round: 4 -----\n",
      "##################################################\n",
      "Best subsequence: _C_C_U_CA_C_C_U_A__C_GU_\n",
      "Depth: 12\n",
      "##################################################\n",
      "\n",
      " ----- Round: 5 -----\n",
      "##################################################\n",
      "Best subsequence: _C_C_U_CA_C_C_U_A__C_GU__C_U_A\n",
      "Depth: 15\n",
      "##################################################\n",
      "\n",
      " ----- Round: 6 -----\n",
      "##################################################\n",
      "Best subsequence: _C_C_U_CA_C_C_U_A__C_GU__C_U_A_C_U_A\n",
      "Depth: 18\n",
      "##################################################\n",
      "\n",
      " ----- Round: 7 -----\n",
      "##################################################\n",
      "Best subsequence: _C_C_U_CA_C_C_U_A__C_GU__C_U_A_C_U_A_CU_\n",
      "Depth: 20\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "from pyaptamer.experiments import AptamerEvalAptaNet\n",
    "from pyaptamer.mcts import MCTS\n",
    "\n",
    "# There can only be one target sequence\n",
    "eval = AptamerEvalAptaNet(pipeline=pipeline, target=protein_sequence[0])\n",
    "\n",
    "mcts = MCTS(experiment=eval)\n",
    "\n",
    "output = mcts.run(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d4397f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UUAUCCACCUCCGCUACUAC'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best sequence\n",
    "output[\"candidate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b2b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyaptamer-latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
