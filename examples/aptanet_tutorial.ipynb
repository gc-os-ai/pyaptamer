{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e8d179",
   "metadata": {},
   "source": [
    "# Binding prediction using AptaNet\n",
    "Step-by-step guide for using AptaNet for binary aptamerâ€“protein binding prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a64683",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook showcases the AptaNet algorithm, a deep learning method that combines sequence-derived (k-mer + PSeAAC) features with RandomForest-based feature selection, and a multi-layer perceptron to predict whether an aptamer and a protein interact (binary classification: aptamer binds/does not bind with the target protein). An overview of the classes and helper functions used in this notebook:\n",
    "\n",
    "- **pairs_to_features**: helper that converts `(aptamer_sequence, protein_sequence)` pairs into feature vectors using k-mer + PSeAAC.\n",
    "- **SkorchAptaNet**: a PyTorch MLP wrapped in Skorch for binary classification.\n",
    "- **load_pfoa_structure**: helper to load the PFOA molecule structure from PDB file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c592d9",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "To train the `AptaNetMLP` the notebook uses:\n",
    "* For `X`:\n",
    "    * 5 random aptamer sequences of length>30 (to satisfy the default lambda value of 30 set in the PSeAAC algorithm).\n",
    "    * Amino acid sequences extracted from the 1GNH protein molecule.\n",
    "    \n",
    "    The aptamer sequences and the amino acid sequences form tuples `(aptamer_sequence, protein_sequence)` to form `X`.\n",
    "* For `y`:\n",
    "    * A random binary value (to indicate if the aptamer binds or not) as dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3737da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data imports\n",
    "import torch\n",
    "\n",
    "from pyaptamer.datasets import load_1gnh_structure\n",
    "from pyaptamer.utils.struct_to_aaseq import struct_to_aaseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2f6701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_sequence = [\n",
    "    \"GGGAGGACGAAGACGACUCGAGACAGGCUAGGGAGGGA\",\n",
    "    \"AAGCGUCGGAUCUACACGUGCGAUAGCUCAGUACGCGGU\",\n",
    "    \"CGGUAUCGAGUACAGGAGUCCGACGGAUAGUCCGGAGC\",\n",
    "    \"UAGCUAGCGAACUAGGCGUAGCUUCGAGUAGCUACGGAA\",\n",
    "    \"GCUAGGACGAUCGCACGUGACCGUCAGUAGCGUAGGAGA\",\n",
    "]\n",
    "\n",
    "gnh = load_1gnh_structure()\n",
    "protein_sequence = struct_to_aaseq(gnh)\n",
    "\n",
    "# Build all combinations (aptamer, protein)\n",
    "X = [(a, p) for a in aptamer_sequence for p in protein_sequence]\n",
    "\n",
    "# Dummy binary labels for the pairs\n",
    "y = torch.randint(0, 2, (len(X),), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ae4ea",
   "metadata": {},
   "source": [
    "## Building the pipeline\n",
    "### Dataset balancing using the Neighbourhood cleaning rule\n",
    "In the `AptaNet` paper, the authors mention using the `NeighbourhoodCleaningRule` from `imblearn` in order to balance the dataset, as in their dataset they had more negative (0) values than positives (1).\n",
    "\n",
    " To build a scikit-learn pipeline, follow these steps:\n",
    "1. Convert the input to the desired (aptamer_sequence, protein_sequence) format.\n",
    "    * OPTIONAL: As mentioned in the paper, perform under-sampling using the  \n",
    "    Neighborhood Cleaning Rule to balance the classes.\n",
    "2. Get the PSeAAC feature vectors for your converted input (using `pairs_to_features`).\n",
    "3. Select the number of features to use from the feature vector (using `RandomForestClassifier`).\n",
    "4. Define the skorch neural network (using `AptaNetMLP`).\n",
    "### Different workflows\n",
    "In this notebook we will cover 3 different workflows one can follow, in ascending order of customizability:\n",
    "\n",
    "1. A minimal workflow with no dataset balancing, while using the in-built pipeline.\n",
    "2. Using your own custom pipeline.\n",
    "3. Dataset balancing, while using your own pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c1997",
   "metadata": {},
   "source": [
    "### First workflow\n",
    "A minimal workflow with no dataset balancing, while using the in-built pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44cc1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use the AptaNet pipeline, you can import it directly\n",
    "from pyaptamer.aptanet import AptaNetPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d782bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AptaNetPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8a0d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline on the aptamer-protein pairs\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae896e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.58\n"
     ]
    }
   ],
   "source": [
    "# Optional: Evaluate training accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a04f9",
   "metadata": {},
   "source": [
    "### Second Worflow\n",
    "\n",
    "Your own custom-built pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6130027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to build your own aptamer pipeline, you should use the following imports\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "\n",
    "from pyaptamer.aptanet._aptanet_nn import AptaNetMLP\n",
    "from pyaptamer.utils._aptanet_utils import pairs_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4a2e277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_transformer = FunctionTransformer(\n",
    "    func=pairs_to_features,\n",
    "    validate=False,\n",
    "    # Optional arguments for pairs_to_features\n",
    "    # example: kw_args={'k': 4, 'pseaac_kwargs': {'lambda_value': 30}}\n",
    "    kw_args={},\n",
    ")\n",
    "\n",
    "selector = SelectFromModel(\n",
    "    estimator=RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=9,\n",
    "        random_state=None,\n",
    "    ),\n",
    "    threshold=\"mean\",\n",
    ")\n",
    "\n",
    "# Define the classifier\n",
    "net = NeuralNetBinaryClassifier(\n",
    "    module=AptaNetMLP,\n",
    "    module__input_dim=None,\n",
    "    module__hidden_dim=128,\n",
    "    module__n_hidden=7,\n",
    "    module__dropout=0.3,\n",
    "    module__output_dim=1,\n",
    "    module__use_lazy=True,\n",
    "    criterion=torch.nn.BCEWithLogitsLoss,\n",
    "    max_epochs=200,\n",
    "    lr=0.00014,\n",
    "    optimizer=torch.optim.RMSprop,\n",
    "    optimizer__alpha=0.9,\n",
    "    optimizer__eps=1e-08,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"features\", feature_transformer),\n",
    "        (\"ncr\", NeighbourhoodCleaningRule()),\n",
    "        (\"selector\", selector),\n",
    "        (\"clf\", net),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8049a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6937\u001b[0m       \u001b[32m0.2857\u001b[0m        \u001b[35m0.7021\u001b[0m  0.0122\n",
      "      2        0.7300       0.2857        \u001b[35m0.7016\u001b[0m  0.0120\n",
      "      3        \u001b[36m0.6757\u001b[0m       0.2857        \u001b[35m0.7011\u001b[0m  0.0129\n",
      "      4        0.7587       0.2857        \u001b[35m0.7008\u001b[0m  0.0144\n",
      "      5        0.7116       0.2857        \u001b[35m0.7005\u001b[0m  0.0144\n",
      "      6        \u001b[36m0.6744\u001b[0m       0.2857        \u001b[35m0.7002\u001b[0m  0.0000\n",
      "      7        0.6881       0.2857        \u001b[35m0.6999\u001b[0m  0.0036\n",
      "      8        0.7367       0.2857        \u001b[35m0.6997\u001b[0m  0.0016\n",
      "      9        \u001b[36m0.6259\u001b[0m       0.2857        \u001b[35m0.6995\u001b[0m  0.0167\n",
      "     10        0.6755       0.2857        \u001b[35m0.6993\u001b[0m  0.0179\n",
      "     11        0.7085       0.2857        \u001b[35m0.6990\u001b[0m  0.0137\n",
      "     12        0.6725       0.2857        \u001b[35m0.6987\u001b[0m  0.0000\n",
      "     13        0.6523       0.2857        \u001b[35m0.6986\u001b[0m  0.0167\n",
      "     14        0.6949       0.2857        \u001b[35m0.6984\u001b[0m  0.0160\n",
      "     15        0.8593       0.2857        \u001b[35m0.6984\u001b[0m  0.0000\n",
      "     16        0.6928       0.2857        \u001b[35m0.6983\u001b[0m  0.0030\n",
      "     17        0.6944       0.2857        \u001b[35m0.6980\u001b[0m  0.0178\n",
      "     18        0.7369       0.2857        \u001b[35m0.6978\u001b[0m  0.0125\n",
      "     19        0.7524       0.2857        \u001b[35m0.6976\u001b[0m  0.0044\n",
      "     20        0.7108       0.2857        \u001b[35m0.6974\u001b[0m  0.0122\n",
      "     21        0.8044       0.2857        \u001b[35m0.6972\u001b[0m  0.0157\n",
      "     22        0.6927       0.2857        \u001b[35m0.6970\u001b[0m  0.0168\n",
      "     23        0.6835       0.2857        \u001b[35m0.6968\u001b[0m  0.0025\n",
      "     24        0.7646       0.2857        \u001b[35m0.6967\u001b[0m  0.0015\n",
      "     25        0.6905       0.2857        \u001b[35m0.6964\u001b[0m  0.0205\n",
      "     26        0.7229       0.2857        \u001b[35m0.6962\u001b[0m  0.0123\n",
      "     27        0.7058       0.2857        \u001b[35m0.6960\u001b[0m  0.0025\n",
      "     28        0.7460       0.2857        \u001b[35m0.6959\u001b[0m  0.0040\n",
      "     29        0.8253       0.2857        \u001b[35m0.6957\u001b[0m  0.0064\n",
      "     30        0.7614       0.2857        \u001b[35m0.6955\u001b[0m  0.0164\n",
      "     31        0.7560       0.2857        \u001b[35m0.6954\u001b[0m  0.0102\n",
      "     32        0.7423       0.2857        \u001b[35m0.6952\u001b[0m  0.0033\n",
      "     33        0.7279       0.2857        \u001b[35m0.6950\u001b[0m  0.0169\n",
      "     34        0.7289       0.2857        \u001b[35m0.6949\u001b[0m  0.0111\n",
      "     35        0.6594       0.2857        \u001b[35m0.6948\u001b[0m  0.0035\n",
      "     36        0.7319       0.2857        \u001b[35m0.6948\u001b[0m  0.0160\n",
      "     37        0.7639       0.2857        \u001b[35m0.6946\u001b[0m  0.0135\n",
      "     38        0.7056       0.2857        \u001b[35m0.6944\u001b[0m  0.0060\n",
      "     39        0.7763       0.2857        \u001b[35m0.6942\u001b[0m  0.0098\n",
      "     40        0.7150       0.2857        \u001b[35m0.6940\u001b[0m  0.0083\n",
      "     41        0.7636       0.2857        \u001b[35m0.6938\u001b[0m  0.0000\n",
      "     42        0.7303       0.2857        \u001b[35m0.6937\u001b[0m  0.0171\n",
      "     43        0.7202       0.2857        \u001b[35m0.6935\u001b[0m  0.0142\n",
      "     44        0.7191       0.2857        \u001b[35m0.6934\u001b[0m  0.0000\n",
      "     45        0.6783       \u001b[32m0.7143\u001b[0m        \u001b[35m0.6931\u001b[0m  0.0060\n",
      "     46        0.7159       0.7143        \u001b[35m0.6930\u001b[0m  0.0106\n",
      "     47        0.6968       0.7143        \u001b[35m0.6929\u001b[0m  0.0070\n",
      "     48        0.6514       0.7143        \u001b[35m0.6927\u001b[0m  0.0082\n",
      "     49        0.6914       0.7143        \u001b[35m0.6926\u001b[0m  0.0013\n",
      "     50        0.6821       0.7143        \u001b[35m0.6923\u001b[0m  0.0169\n",
      "     51        \u001b[36m0.6183\u001b[0m       0.7143        \u001b[35m0.6922\u001b[0m  0.0132\n",
      "     52        0.7294       0.7143        \u001b[35m0.6921\u001b[0m  0.0061\n",
      "     53        0.7171       0.7143        \u001b[35m0.6919\u001b[0m  0.0066\n",
      "     54        0.7023       0.7143        \u001b[35m0.6917\u001b[0m  0.0070\n",
      "     55        0.7287       0.7143        \u001b[35m0.6915\u001b[0m  0.0049\n",
      "     56        0.6470       0.7143        \u001b[35m0.6914\u001b[0m  0.0126\n",
      "     57        0.6830       0.7143        \u001b[35m0.6912\u001b[0m  0.0024\n",
      "     58        0.7164       0.7143        \u001b[35m0.6910\u001b[0m  0.0143\n",
      "     59        0.6961       0.7143        \u001b[35m0.6908\u001b[0m  0.0000\n",
      "     60        0.7353       0.7143        \u001b[35m0.6907\u001b[0m  0.0166\n",
      "     61        0.7734       0.7143        \u001b[35m0.6906\u001b[0m  0.0073\n",
      "     62        0.7042       0.7143        \u001b[35m0.6904\u001b[0m  0.0044\n",
      "     63        0.7258       0.7143        \u001b[35m0.6902\u001b[0m  0.0127\n",
      "     64        0.6450       0.7143        \u001b[35m0.6901\u001b[0m  0.0014\n",
      "     65        0.7196       0.7143        \u001b[35m0.6900\u001b[0m  0.0173\n",
      "     66        0.7540       0.7143        \u001b[35m0.6899\u001b[0m  0.0107\n",
      "     67        0.6402       0.7143        \u001b[35m0.6896\u001b[0m  0.0090\n",
      "     68        0.7269       0.7143        \u001b[35m0.6895\u001b[0m  0.0080\n",
      "     69        0.7428       0.7143        \u001b[35m0.6893\u001b[0m  0.0000\n",
      "     70        0.6888       0.7143        \u001b[35m0.6891\u001b[0m  0.0030\n",
      "     71        0.7205       0.7143        \u001b[35m0.6890\u001b[0m  0.0137\n",
      "     72        0.7053       0.7143        \u001b[35m0.6888\u001b[0m  0.0000\n",
      "     73        0.6870       0.7143        \u001b[35m0.6888\u001b[0m  0.0072\n",
      "     74        0.7202       0.7143        \u001b[35m0.6885\u001b[0m  0.0147\n",
      "     75        0.8050       0.7143        \u001b[35m0.6884\u001b[0m  0.0124\n",
      "     76        0.7667       0.7143        \u001b[35m0.6884\u001b[0m  0.0059\n",
      "     77        0.7254       0.7143        \u001b[35m0.6882\u001b[0m  0.0136\n",
      "     78        0.7625       0.7143        \u001b[35m0.6881\u001b[0m  0.0058\n",
      "     79        0.6705       0.7143        0.6881  0.0080\n",
      "     80        0.7003       0.7143        0.6881  0.0074\n",
      "     81        0.7439       0.7143        \u001b[35m0.6878\u001b[0m  0.0000\n",
      "     82        0.6577       0.7143        \u001b[35m0.6877\u001b[0m  0.0198\n",
      "     83        0.7087       0.7143        \u001b[35m0.6874\u001b[0m  0.0000\n",
      "     84        0.7105       0.7143        \u001b[35m0.6873\u001b[0m  0.0075\n",
      "     85        0.7443       0.7143        \u001b[35m0.6871\u001b[0m  0.0069\n",
      "     86        0.7532       0.7143        \u001b[35m0.6870\u001b[0m  0.0009\n",
      "     87        0.6886       0.7143        \u001b[35m0.6869\u001b[0m  0.0157\n",
      "     88        0.7706       0.7143        \u001b[35m0.6868\u001b[0m  0.0000\n",
      "     89        0.7498       0.7143        \u001b[35m0.6867\u001b[0m  0.0088\n",
      "     90        0.6768       0.7143        \u001b[35m0.6866\u001b[0m  0.0075\n",
      "     91        0.7302       0.7143        \u001b[35m0.6864\u001b[0m  0.0024\n",
      "     92        0.6939       0.7143        \u001b[35m0.6863\u001b[0m  0.0147\n",
      "     93        0.6405       0.7143        \u001b[35m0.6862\u001b[0m  0.0106\n",
      "     94        0.7163       0.7143        \u001b[35m0.6860\u001b[0m  0.0107\n",
      "     95        0.6467       0.7143        \u001b[35m0.6858\u001b[0m  0.0030\n",
      "     96        0.7085       0.7143        \u001b[35m0.6856\u001b[0m  0.0173\n",
      "     97        0.7035       0.7143        \u001b[35m0.6855\u001b[0m  0.0000\n",
      "     98        0.6500       0.7143        \u001b[35m0.6853\u001b[0m  0.0166\n",
      "     99        0.7902       0.7143        \u001b[35m0.6852\u001b[0m  0.0170\n",
      "    100        0.6908       0.7143        0.6853  0.0005\n",
      "    101        0.7206       0.7143        \u001b[35m0.6850\u001b[0m  0.0066\n",
      "    102        0.6500       0.7143        \u001b[35m0.6849\u001b[0m  0.0146\n",
      "    103        0.7577       0.7143        \u001b[35m0.6847\u001b[0m  0.0127\n",
      "    104        0.6913       0.7143        \u001b[35m0.6846\u001b[0m  0.0057\n",
      "    105        0.7220       0.7143        \u001b[35m0.6844\u001b[0m  0.0130\n",
      "    106        0.6319       0.7143        \u001b[35m0.6843\u001b[0m  0.0072\n",
      "    107        0.7303       0.7143        \u001b[35m0.6842\u001b[0m  0.0101\n",
      "    108        0.7098       0.7143        \u001b[35m0.6841\u001b[0m  0.0097\n",
      "    109        0.7167       0.7143        \u001b[35m0.6840\u001b[0m  0.0055\n",
      "    110        \u001b[36m0.6141\u001b[0m       0.7143        \u001b[35m0.6838\u001b[0m  0.0068\n",
      "    111        0.6681       0.7143        \u001b[35m0.6836\u001b[0m  0.0070\n",
      "    112        0.6627       0.7143        \u001b[35m0.6835\u001b[0m  0.0145\n",
      "    113        0.7158       0.7143        \u001b[35m0.6834\u001b[0m  0.0044\n",
      "    114        0.6977       0.7143        \u001b[35m0.6833\u001b[0m  0.0132\n",
      "    115        0.6481       0.7143        \u001b[35m0.6831\u001b[0m  0.0015\n",
      "    116        0.6944       0.7143        \u001b[35m0.6829\u001b[0m  0.0143\n",
      "    117        0.7081       0.7143        \u001b[35m0.6827\u001b[0m  0.0023\n",
      "    118        0.7293       0.7143        \u001b[35m0.6826\u001b[0m  0.0128\n",
      "    119        0.6957       0.7143        \u001b[35m0.6825\u001b[0m  0.0066\n",
      "    120        0.7458       0.7143        \u001b[35m0.6825\u001b[0m  0.0079\n",
      "    121        0.7566       0.7143        \u001b[35m0.6824\u001b[0m  0.0098\n",
      "    122        0.6793       0.7143        \u001b[35m0.6822\u001b[0m  0.0089\n",
      "    123        0.8038       0.7143        \u001b[35m0.6821\u001b[0m  0.0065\n",
      "    124        \u001b[36m0.6109\u001b[0m       0.7143        \u001b[35m0.6820\u001b[0m  0.0134\n",
      "    125        0.6864       0.7143        \u001b[35m0.6817\u001b[0m  0.0114\n",
      "    126        0.7176       0.7143        \u001b[35m0.6816\u001b[0m  0.0034\n",
      "    127        0.7795       0.7143        \u001b[35m0.6815\u001b[0m  0.0151\n",
      "    128        0.7390       0.7143        \u001b[35m0.6813\u001b[0m  0.0036\n",
      "    129        0.7669       0.7143        \u001b[35m0.6813\u001b[0m  0.0064\n",
      "    130        0.7923       0.7143        \u001b[35m0.6813\u001b[0m  0.0131\n",
      "    131        0.7689       0.7143        \u001b[35m0.6811\u001b[0m  0.0080\n",
      "    132        0.7336       0.7143        \u001b[35m0.6810\u001b[0m  0.0089\n",
      "    133        0.6774       0.7143        \u001b[35m0.6809\u001b[0m  0.0108\n",
      "    134        0.6455       0.7143        \u001b[35m0.6807\u001b[0m  0.0102\n",
      "    135        0.6534       0.7143        \u001b[35m0.6806\u001b[0m  0.0065\n",
      "    136        0.6879       0.7143        \u001b[35m0.6805\u001b[0m  0.0149\n",
      "    137        0.6674       0.7143        \u001b[35m0.6804\u001b[0m  0.0075\n",
      "    138        0.6899       0.7143        \u001b[35m0.6802\u001b[0m  0.0078\n",
      "    139        0.7537       0.7143        \u001b[35m0.6800\u001b[0m  0.0100\n",
      "    140        0.7665       0.7143        \u001b[35m0.6799\u001b[0m  0.0125\n",
      "    141        0.7449       0.7143        \u001b[35m0.6798\u001b[0m  0.0014\n",
      "    142        0.6832       0.7143        \u001b[35m0.6796\u001b[0m  0.0160\n",
      "    143        0.7477       0.7143        \u001b[35m0.6794\u001b[0m  0.0135\n",
      "    144        0.7169       0.7143        \u001b[35m0.6793\u001b[0m  0.0173\n",
      "    145        0.6340       0.7143        \u001b[35m0.6791\u001b[0m  0.0126\n",
      "    146        0.7514       0.7143        \u001b[35m0.6789\u001b[0m  0.0054\n",
      "    147        0.7003       0.7143        \u001b[35m0.6787\u001b[0m  0.0108\n",
      "    148        0.6833       0.7143        \u001b[35m0.6785\u001b[0m  0.0129\n",
      "    149        0.6850       0.7143        \u001b[35m0.6785\u001b[0m  0.0136\n",
      "    150        0.7528       0.7143        \u001b[35m0.6783\u001b[0m  0.0118\n",
      "    151        0.6950       0.7143        \u001b[35m0.6781\u001b[0m  0.0070\n",
      "    152        0.7455       0.7143        0.6781  0.0067\n",
      "    153        0.7319       0.7143        \u001b[35m0.6781\u001b[0m  0.0110\n",
      "    154        0.6561       0.7143        \u001b[35m0.6779\u001b[0m  0.0100\n",
      "    155        0.8147       0.7143        \u001b[35m0.6778\u001b[0m  0.0079\n",
      "    156        0.6862       0.7143        \u001b[35m0.6776\u001b[0m  0.0050\n",
      "    157        0.7494       0.7143        \u001b[35m0.6775\u001b[0m  0.0020\n",
      "    158        0.7648       0.7143        \u001b[35m0.6775\u001b[0m  0.0171\n",
      "    159        0.7366       0.7143        \u001b[35m0.6774\u001b[0m  0.0096\n",
      "    160        0.7718       0.7143        \u001b[35m0.6773\u001b[0m  0.0096\n",
      "    161        0.6897       0.7143        \u001b[35m0.6772\u001b[0m  0.0099\n",
      "    162        0.7274       0.7143        \u001b[35m0.6771\u001b[0m  0.0029\n",
      "    163        0.6692       0.7143        \u001b[35m0.6769\u001b[0m  0.0053\n",
      "    164        0.6808       0.7143        \u001b[35m0.6768\u001b[0m  0.0132\n",
      "    165        0.7157       0.7143        \u001b[35m0.6767\u001b[0m  0.0020\n",
      "    166        0.7220       0.7143        \u001b[35m0.6766\u001b[0m  0.0137\n",
      "    167        0.6326       0.7143        \u001b[35m0.6765\u001b[0m  0.0003\n",
      "    168        0.7280       0.7143        \u001b[35m0.6763\u001b[0m  0.0052\n",
      "    169        0.7501       0.7143        \u001b[35m0.6762\u001b[0m  0.0135\n",
      "    170        \u001b[36m0.6106\u001b[0m       0.7143        \u001b[35m0.6762\u001b[0m  0.0077\n",
      "    171        0.6939       0.7143        \u001b[35m0.6761\u001b[0m  0.0093\n",
      "    172        0.6391       0.7143        \u001b[35m0.6759\u001b[0m  0.0070\n",
      "    173        0.7596       0.7143        \u001b[35m0.6757\u001b[0m  0.0049\n",
      "    174        0.6839       0.7143        \u001b[35m0.6756\u001b[0m  0.0127\n",
      "    175        0.7076       0.7143        0.6756  0.0029\n",
      "    176        0.6526       0.7143        \u001b[35m0.6755\u001b[0m  0.0138\n",
      "    177        0.6436       0.7143        \u001b[35m0.6753\u001b[0m  0.0014\n",
      "    178        0.6990       0.7143        \u001b[35m0.6751\u001b[0m  0.0163\n",
      "    179        0.7259       0.7143        \u001b[35m0.6750\u001b[0m  0.0108\n",
      "    180        0.6845       0.7143        \u001b[35m0.6749\u001b[0m  0.0060\n",
      "    181        0.6940       0.7143        \u001b[35m0.6749\u001b[0m  0.0119\n",
      "    182        0.7502       0.7143        \u001b[35m0.6748\u001b[0m  0.0072\n",
      "    183        0.7452       0.7143        \u001b[35m0.6748\u001b[0m  0.0085\n",
      "    184        0.7306       0.7143        \u001b[35m0.6745\u001b[0m  0.0100\n",
      "    185        0.6896       0.7143        \u001b[35m0.6745\u001b[0m  0.0039\n",
      "    186        0.6916       0.7143        \u001b[35m0.6745\u001b[0m  0.0122\n",
      "    187        0.7038       0.7143        \u001b[35m0.6743\u001b[0m  0.0097\n",
      "    188        0.7461       0.7143        \u001b[35m0.6742\u001b[0m  0.0068\n",
      "    189        0.7126       0.7143        \u001b[35m0.6741\u001b[0m  0.0143\n",
      "    190        0.7147       0.7143        \u001b[35m0.6740\u001b[0m  0.0000\n",
      "    191        0.7148       0.7143        \u001b[35m0.6739\u001b[0m  0.0155\n",
      "    192        0.6893       0.7143        \u001b[35m0.6738\u001b[0m  0.0092\n",
      "    193        0.6558       0.7143        \u001b[35m0.6738\u001b[0m  0.0106\n",
      "    194        0.7047       0.7143        \u001b[35m0.6736\u001b[0m  0.0004\n",
      "    195        0.6840       0.7143        \u001b[35m0.6735\u001b[0m  0.0152\n",
      "    196        0.7148       0.7143        \u001b[35m0.6734\u001b[0m  0.0000\n",
      "    197        0.7019       0.7143        \u001b[35m0.6733\u001b[0m  0.0070\n",
      "    198        0.7712       0.7143        0.6733  0.0110\n",
      "    199        0.7365       0.7143        \u001b[35m0.6732\u001b[0m  0.0014\n",
      "    200        0.6910       0.7143        \u001b[35m0.6731\u001b[0m  0.0074\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the aptamer-protein pairs\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f00091db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.58\n"
     ]
    }
   ],
   "source": [
    "# Optional: Evaluate training accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db693e",
   "metadata": {},
   "source": [
    "### Third workflow\n",
    "Dataset balancing using under-sampling, while using your own pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to build your own aptamer pipeline, you should use the following imports\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from pyaptamer.aptanet import AptaNetClassifier, AptaNetPipeline\n",
    "from pyaptamer.utils._aptanet_utils import pairs_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0cf0bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: If you want to use the Neighborhood Cleaning Rule for under-sampling\n",
    "# NOTE: If you want to use under-sampling, you need to install imbalanced-learn\n",
    "# and use the Pipeline from imblearn\n",
    "# %pip install imblearn\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13fb1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_transformer = FunctionTransformer(\n",
    "    func=pairs_to_features,\n",
    "    validate=False,\n",
    "    # Optional arguments for pairs_to_features\n",
    "    # example: kw_args={'k': 4, 'pseaac_kwargs': {'lambda_value': 30}}\n",
    "    kw_args={},\n",
    ")\n",
    "\n",
    "# AptaNetClassifier encapsulates the \"selector\" and \"net\" mentioned in Workflow 2\n",
    "clf = AptaNetClassifier()\n",
    "\n",
    "model = Pipeline(\n",
    "    [\n",
    "        (\"features\", feature_transformer),\n",
    "        (\"ncr\", NeighbourhoodCleaningRule()),\n",
    "        (\"classifier\", clf),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = AptaNetPipeline(classifier=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ed76399",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Fit the pipeline on the aptamer-protein pairs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Predict the labels for the training data\u001b[39;00m\n\u001b[32m      5\u001b[39m y_pred = pipeline.predict(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\pyaptamer\\pyaptamer\\aptanet\\_pipeline.py:79\u001b[39m, in \u001b[36mfit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer-latest\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer-latest\\Lib\\site-packages\\sklearn\\pipeline.py:663\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    658\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    659\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    660\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    661\u001b[39m             all_params=params,\n\u001b[32m    662\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer-latest\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer-latest\\Lib\\site-packages\\imblearn\\pipeline.py:518\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    511\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    512\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `transform_input` parameter is not supported in scikit-learn \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    513\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mversions prior to 1.4. Please upgrade to scikit-learn 1.4 or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlater.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n\u001b[32m    517\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m Xt, yt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    520\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer-latest\\Lib\\site-packages\\imblearn\\pipeline.py:430\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    422\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    423\u001b[39m     step_idx=step_idx,\n\u001b[32m    424\u001b[39m     step_params=routed_params[name],\n\u001b[32m    425\u001b[39m     all_params=raw_params,\n\u001b[32m    426\u001b[39m )\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cloned_transformer, \u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[32m    428\u001b[39m     cloned_transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    429\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cloned_transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_resample\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    440\u001b[39m     X, y, fitted_transformer = fit_resample_one_cached(\n\u001b[32m    441\u001b[39m         cloned_transformer,\n\u001b[32m    442\u001b[39m         X,\n\u001b[32m   (...)\u001b[39m\u001b[32m    446\u001b[39m         params=routed_params[name],\n\u001b[32m    447\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer-latest\\Lib\\site-packages\\joblib\\memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer-latest\\Lib\\site-packages\\imblearn\\pipeline.py:1383\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1382\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1383\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1384\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1385\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1386\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1387\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer-latest\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer-latest\\Lib\\site-packages\\sklearn\\base.py:897\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, **fit_params).transform(X)\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer-latest\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer-latest\\Lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:260\u001b[39m, in \u001b[36mFunctionTransformer.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[32m    247\u001b[39m \n\u001b[32m    248\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m \u001b[33;03m    Transformed input.\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    259\u001b[39m X = \u001b[38;5;28mself\u001b[39m._check_input(X, reset=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw_args\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m output_config = _get_output_config(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)[\u001b[33m\"\u001b[39m\u001b[33mdense\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(out, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.feature_names_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    264\u001b[39m     \u001b[38;5;66;03m# check the consistency between the column provided by `transform` and\u001b[39;00m\n\u001b[32m    265\u001b[39m     \u001b[38;5;66;03m# the column names provided by `get_feature_names_out`.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\satvm\\miniconda3\\envs\\pyaptamer-latest\\Lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:387\u001b[39m, in \u001b[36mFunctionTransformer._transform\u001b[39m\u001b[34m(self, X, func, kw_args)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    385\u001b[39m     func = _identity\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkw_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkw_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\pyaptamer\\pyaptamer\\utils\\_aptanet_utils.py:90\u001b[39m, in \u001b[36mpairs_to_features\u001b[39m\u001b[34m(X, k)\u001b[39m\n\u001b[32m     88\u001b[39m     kmer = generate_kmer_vecs(aptamer_seq, k=k)\n\u001b[32m     89\u001b[39m     pseaac_vec = np.asarray(pseaac.transform(protein_seq))\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     feats.append(np.concatenate([kmer, pseaac_vec]))\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# Ensure float32 for PyTorch compatibility\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.vstack(feats).astype(np.float32)\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the aptamer-protein pairs\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945dc876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.48\n"
     ]
    }
   ],
   "source": [
    "# Optional: Evaluate training accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyaptamer-latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
