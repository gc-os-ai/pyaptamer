{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e8d179",
   "metadata": {},
   "source": [
    "# Binding prediction using AptaNet\n",
    "Step-by-step guide for using AptaNet for binary aptamerâ€“protein binding prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a64683",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook showcases the AptaNet algorithm, a deep learning method that combines sequence-derived (k-mer + PSeAAC) features with RandomForest-based feature selection, and a multi-layer perceptron to predict whether an aptamer and a protein interact (binary classification). An overview of the classes and helper functions used in this notebook:\n",
    "\n",
    "- **pairs_to_features**: helper that converts `(aptamer_sequence, protein_sequence)` pairs into feature vectors using k-mer + PSeAAC.\n",
    "- **FeatureSelector**: a Random Forest-based transformer that selects important features.\n",
    "- **SkorchAptaNet**: a PyTorch MLP wrapped in Skorch for binary classification.\n",
    "- **load_pfoa_structure**: helper to load the PFOA molecule structure from PDB file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c592d9",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "To train the `AptaNetMLP` the notebook uses:\n",
    "* For `X`:\n",
    "    * 5 random aptamer sequences of length>30 (to satisfy the default lambda value of 30 set in the PSeAAC algorithm).\n",
    "    * Amino acid sequences extracted from the 1GNH protein molecule.\n",
    "    \n",
    "    The aptamer sequences and the amino acid sequences form tuples `(aptamer_sequence, protein_sequence)` to form `X`.\n",
    "* For `y`:\n",
    "    * A random binary value (to indicate if the aptamer binds or not) as dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3737da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data imports\n",
    "import torch\n",
    "\n",
    "from pyaptamer.datasets import load_1gnh_structure\n",
    "from pyaptamer.utils.struct_to_aaseq import struct_to_aaseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f6701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aptamer_sequence = [\n",
    "    \"GGGAGGACGAAGACGACUCGAGACAGGCUAGGGAGGGA\",\n",
    "    \"AAGCGUCGGAUCUACACGUGCGAUAGCUCAGUACGCGGU\",\n",
    "    \"CGGUAUCGAGUACAGGAGUCCGACGGAUAGUCCGGAGC\",\n",
    "    \"UAGCUAGCGAACUAGGCGUAGCUUCGAGUAGCUACGGAA\",\n",
    "    \"GCUAGGACGAUCGCACGUGACCGUCAGUAGCGUAGGAGA\",\n",
    "]\n",
    "\n",
    "gnh = load_1gnh_structure()\n",
    "protein_sequence = struct_to_aaseq(gnh)\n",
    "\n",
    "# Build all combinations (aptamer, protein)\n",
    "X = [(a, p) for a in aptamer_sequence for p in protein_sequence]\n",
    "\n",
    "# Dummy binary labels for the pairs\n",
    "y = torch.randint(0, 2, (len(X),), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ae4ea",
   "metadata": {},
   "source": [
    "## Build your own pipeline\n",
    "### The Neighbourhood cleaning rule\n",
    "In the `AptaNet` paper, the authors mention using the `NeighbourhoodCleaningRule` from `imblearn` in order to balance the dataset, as in their dataset they had more negative (0) values than positives (1).\n",
    "\n",
    " To build a scikit-learn pipeline, follow these steps:\n",
    "1. Convert the input to the desired (aptamer_sequence, protein_sequence) format.\n",
    "    * OPTIONAL: As mentioned in the paper, perform under-sampling using the  \n",
    "    Neighborhood Cleaning Rule to balance the classes.\n",
    "2. Get the PSeAAC feature vectors for your converted input (using `pairs_to_features`).\n",
    "3. Select the number of features to use from the feature vector (using `FeatureSelector`).\n",
    "4. Define the skorch neural network (using `AptaNetMLP`).\n",
    "### Different workflows\n",
    "In this notebook we will cover 3 different workflows one can follow, in ascending order of customizability:\n",
    "\n",
    "1. A minimal workflow with no dataset balancing, while using the in-built pipeline.\n",
    "2. Using your own custom pipeline.\n",
    "3. Dataset balancing, while using your own pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c1997",
   "metadata": {},
   "source": [
    "### First workflow\n",
    "A minimal workflow with no dataset balancing, while using the in-built pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44cc1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use the AptaNet pipeline, you can import it directly\n",
    "from pyaptamer.aptanet import AptaNetPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d782bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AptaNetPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8a0d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline on the aptamer-protein pairs\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae896e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Optional: Evaluate training accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a04f9",
   "metadata": {},
   "source": [
    "### Second Worflow\n",
    "\n",
    "Your own custom-built pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6130027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you to build your own aptamer pipeline, you should use the following imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "\n",
    "from pyaptamer.aptanet._aptanet_nn import AptaNetMLP\n",
    "from pyaptamer.utils._aptanet_utils import pairs_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a2e277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_transformer = FunctionTransformer(\n",
    "    func=pairs_to_features,\n",
    "    validate=False,\n",
    "    # Optional arguments for pairs_to_features\n",
    "    # example: kw_args={'k': 4, 'pseaac_kwargs': {'lambda_value': 30}}\n",
    "    kw_args={},\n",
    ")\n",
    "\n",
    "selector = SelectFromModel(\n",
    "    estimator=RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=9,\n",
    "        random_state=None,\n",
    "    ),\n",
    "    threshold=\"mean\",\n",
    ")\n",
    "\n",
    "# Define the classifier\n",
    "net = NeuralNetBinaryClassifier(\n",
    "    module=AptaNetMLP,\n",
    "    module__input_dim=None,\n",
    "    module__hidden_dim=128,\n",
    "    module__n_hidden=7,\n",
    "    module__dropout=0.3,\n",
    "    module__output_dim=1,\n",
    "    module__use_lazy=True,\n",
    "    criterion=torch.nn.BCEWithLogitsLoss,\n",
    "    max_epochs=200,\n",
    "    lr=0.00014,\n",
    "    optimizer=torch.optim.RMSprop,\n",
    "    optimizer__alpha=0.9,\n",
    "    optimizer__eps=1e-08,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"features\", feature_transformer),\n",
    "        (\"selector\", selector),\n",
    "        (\"clf\", net),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8049a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7086\u001b[0m       \u001b[32m0.4000\u001b[0m        \u001b[35m0.7011\u001b[0m  0.0080\n",
      "      2        0.7620       0.4000        \u001b[35m0.7009\u001b[0m  0.0105\n",
      "      3        0.7134       0.4000        \u001b[35m0.7007\u001b[0m  0.0110\n",
      "      4        0.7606       0.4000        \u001b[35m0.7006\u001b[0m  0.0080\n",
      "      5        0.7394       0.4000        \u001b[35m0.7005\u001b[0m  0.0090\n",
      "      6        0.7378       0.4000        \u001b[35m0.7004\u001b[0m  0.0100\n",
      "      7        \u001b[36m0.6926\u001b[0m       0.4000        \u001b[35m0.7003\u001b[0m  0.0090\n",
      "      8        0.7217       0.4000        \u001b[35m0.7002\u001b[0m  0.0090\n",
      "      9        0.7119       0.4000        \u001b[35m0.7001\u001b[0m  0.0100\n",
      "     10        0.7540       0.4000        \u001b[35m0.7000\u001b[0m  0.0090\n",
      "     11        0.7884       0.4000        \u001b[35m0.6999\u001b[0m  0.0085\n",
      "     12        \u001b[36m0.6804\u001b[0m       0.4000        \u001b[35m0.6998\u001b[0m  0.0090\n",
      "     13        0.7759       0.4000        \u001b[35m0.6997\u001b[0m  0.0090\n",
      "     14        0.7175       0.4000        \u001b[35m0.6996\u001b[0m  0.0080\n",
      "     15        0.8031       0.4000        \u001b[35m0.6996\u001b[0m  0.0090\n",
      "     16        0.7258       0.4000        \u001b[35m0.6995\u001b[0m  0.0080\n",
      "     17        0.7431       0.4000        \u001b[35m0.6995\u001b[0m  0.0080\n",
      "     18        0.7382       0.4000        \u001b[35m0.6995\u001b[0m  0.0090\n",
      "     19        0.7546       0.4000        \u001b[35m0.6994\u001b[0m  0.0080\n",
      "     20        0.7104       0.4000        \u001b[35m0.6993\u001b[0m  0.0092\n",
      "     21        0.7625       0.4000        \u001b[35m0.6992\u001b[0m  0.0090\n",
      "     22        0.7284       0.4000        \u001b[35m0.6992\u001b[0m  0.0080\n",
      "     23        0.8167       0.4000        \u001b[35m0.6991\u001b[0m  0.0090\n",
      "     24        0.8073       0.4000        \u001b[35m0.6991\u001b[0m  0.0080\n",
      "     25        0.7150       0.4000        \u001b[35m0.6990\u001b[0m  0.0090\n",
      "     26        0.7580       0.4000        \u001b[35m0.6990\u001b[0m  0.0090\n",
      "     27        0.7316       0.4000        \u001b[35m0.6989\u001b[0m  0.0080\n",
      "     28        0.7701       0.4000        \u001b[35m0.6989\u001b[0m  0.0070\n",
      "     29        0.6993       0.4000        \u001b[35m0.6988\u001b[0m  0.0085\n",
      "     30        0.7347       0.4000        \u001b[35m0.6987\u001b[0m  0.0100\n",
      "     31        0.7335       0.4000        \u001b[35m0.6987\u001b[0m  0.0080\n",
      "     32        \u001b[36m0.6766\u001b[0m       0.4000        \u001b[35m0.6986\u001b[0m  0.0080\n",
      "     33        0.7281       0.4000        \u001b[35m0.6985\u001b[0m  0.0100\n",
      "     34        0.7615       0.4000        \u001b[35m0.6984\u001b[0m  0.0080\n",
      "     35        0.7755       0.4000        \u001b[35m0.6984\u001b[0m  0.0090\n",
      "     36        0.8363       0.4000        \u001b[35m0.6983\u001b[0m  0.0090\n",
      "     37        0.7219       0.4000        \u001b[35m0.6982\u001b[0m  0.0080\n",
      "     38        0.8120       0.4000        \u001b[35m0.6982\u001b[0m  0.0085\n",
      "     39        0.7458       0.4000        \u001b[35m0.6982\u001b[0m  0.0080\n",
      "     40        0.7006       0.4000        \u001b[35m0.6981\u001b[0m  0.0070\n",
      "     41        0.7644       0.4000        \u001b[35m0.6980\u001b[0m  0.0080\n",
      "     42        0.7484       0.4000        \u001b[35m0.6980\u001b[0m  0.0070\n",
      "     43        0.7532       0.4000        \u001b[35m0.6979\u001b[0m  0.0070\n",
      "     44        0.7664       0.4000        \u001b[35m0.6978\u001b[0m  0.0060\n",
      "     45        0.7197       0.4000        \u001b[35m0.6978\u001b[0m  0.0090\n",
      "     46        0.7829       0.4000        \u001b[35m0.6977\u001b[0m  0.0060\n",
      "     47        0.6894       0.4000        \u001b[35m0.6977\u001b[0m  0.0070\n",
      "     48        \u001b[36m0.6624\u001b[0m       0.4000        \u001b[35m0.6976\u001b[0m  0.0070\n",
      "     49        0.7067       0.4000        \u001b[35m0.6976\u001b[0m  0.0085\n",
      "     50        0.7054       0.4000        \u001b[35m0.6975\u001b[0m  0.0060\n",
      "     51        0.6800       0.4000        \u001b[35m0.6975\u001b[0m  0.0070\n",
      "     52        0.7082       0.4000        \u001b[35m0.6974\u001b[0m  0.0060\n",
      "     53        0.7916       0.4000        \u001b[35m0.6974\u001b[0m  0.0070\n",
      "     54        0.7084       0.4000        \u001b[35m0.6974\u001b[0m  0.0060\n",
      "     55        0.7149       0.4000        \u001b[35m0.6974\u001b[0m  0.0070\n",
      "     56        0.7080       0.4000        \u001b[35m0.6973\u001b[0m  0.0070\n",
      "     57        0.7258       0.4000        \u001b[35m0.6973\u001b[0m  0.0070\n",
      "     58        0.7157       0.4000        \u001b[35m0.6973\u001b[0m  0.0070\n",
      "     59        0.7318       0.4000        \u001b[35m0.6973\u001b[0m  0.0070\n",
      "     60        0.6775       0.4000        \u001b[35m0.6972\u001b[0m  0.0060\n",
      "     61        0.7458       0.4000        \u001b[35m0.6972\u001b[0m  0.0085\n",
      "     62        0.6857       0.4000        \u001b[35m0.6971\u001b[0m  0.0070\n",
      "     63        0.7780       0.4000        0.6971  0.0060\n",
      "     64        0.6656       0.4000        \u001b[35m0.6971\u001b[0m  0.0090\n",
      "     65        0.7594       0.4000        \u001b[35m0.6971\u001b[0m  0.0070\n",
      "     66        0.6867       0.4000        \u001b[35m0.6970\u001b[0m  0.0080\n",
      "     67        0.7595       0.4000        \u001b[35m0.6969\u001b[0m  0.0080\n",
      "     68        0.7154       0.4000        \u001b[35m0.6968\u001b[0m  0.0070\n",
      "     69        0.7283       0.4000        \u001b[35m0.6968\u001b[0m  0.0080\n",
      "     70        0.7632       0.4000        \u001b[35m0.6967\u001b[0m  0.0070\n",
      "     71        0.7024       0.4000        0.6968  0.0060\n",
      "     72        0.7471       0.4000        \u001b[35m0.6967\u001b[0m  0.0085\n",
      "     73        0.7343       0.4000        \u001b[35m0.6966\u001b[0m  0.0090\n",
      "     74        0.7263       0.4000        \u001b[35m0.6966\u001b[0m  0.0060\n",
      "     75        0.7241       0.4000        \u001b[35m0.6965\u001b[0m  0.0100\n",
      "     76        0.7469       0.4000        \u001b[35m0.6964\u001b[0m  0.0070\n",
      "     77        0.6784       0.4000        \u001b[35m0.6964\u001b[0m  0.0070\n",
      "     78        0.6815       0.4000        \u001b[35m0.6963\u001b[0m  0.0070\n",
      "     79        0.7270       0.4000        \u001b[35m0.6962\u001b[0m  0.0060\n",
      "     80        0.7547       0.4000        \u001b[35m0.6962\u001b[0m  0.0070\n",
      "     81        0.6932       0.4000        \u001b[35m0.6962\u001b[0m  0.0070\n",
      "     82        0.7009       0.4000        \u001b[35m0.6962\u001b[0m  0.0070\n",
      "     83        0.6902       0.4000        \u001b[35m0.6961\u001b[0m  0.0073\n",
      "     84        0.6854       0.4000        \u001b[35m0.6961\u001b[0m  0.0100\n",
      "     85        0.7395       0.4000        \u001b[35m0.6961\u001b[0m  0.0070\n",
      "     86        0.7334       0.4000        \u001b[35m0.6961\u001b[0m  0.0070\n",
      "     87        0.7291       0.4000        \u001b[35m0.6960\u001b[0m  0.0070\n",
      "     88        0.6627       0.4000        \u001b[35m0.6959\u001b[0m  0.0070\n",
      "     89        0.7037       0.4000        \u001b[35m0.6959\u001b[0m  0.0070\n",
      "     90        \u001b[36m0.6545\u001b[0m       0.4000        \u001b[35m0.6958\u001b[0m  0.0100\n",
      "     91        \u001b[36m0.6357\u001b[0m       0.4000        \u001b[35m0.6958\u001b[0m  0.0090\n",
      "     92        0.6926       0.4000        \u001b[35m0.6957\u001b[0m  0.0070\n",
      "     93        0.7459       0.4000        \u001b[35m0.6956\u001b[0m  0.0070\n",
      "     94        0.6836       0.4000        \u001b[35m0.6956\u001b[0m  0.0075\n",
      "     95        0.7365       0.4000        \u001b[35m0.6955\u001b[0m  0.0080\n",
      "     96        0.7086       0.4000        \u001b[35m0.6954\u001b[0m  0.0080\n",
      "     97        0.7055       0.4000        \u001b[35m0.6953\u001b[0m  0.0060\n",
      "     98        0.7243       0.4000        \u001b[35m0.6952\u001b[0m  0.0060\n",
      "     99        0.7462       0.4000        \u001b[35m0.6952\u001b[0m  0.0060\n",
      "    100        0.6922       0.4000        \u001b[35m0.6951\u001b[0m  0.0070\n",
      "    101        0.7581       0.4000        \u001b[35m0.6951\u001b[0m  0.0090\n",
      "    102        0.6824       0.4000        \u001b[35m0.6951\u001b[0m  0.0080\n",
      "    103        0.7131       0.4000        \u001b[35m0.6950\u001b[0m  0.0060\n",
      "    104        0.7241       0.4000        \u001b[35m0.6950\u001b[0m  0.0080\n",
      "    105        0.7648       0.4000        \u001b[35m0.6950\u001b[0m  0.0065\n",
      "    106        0.7702       0.4000        \u001b[35m0.6949\u001b[0m  0.0070\n",
      "    107        0.7226       0.4000        \u001b[35m0.6948\u001b[0m  0.0070\n",
      "    108        0.7205       0.4000        \u001b[35m0.6947\u001b[0m  0.0070\n",
      "    109        0.7202       0.4000        \u001b[35m0.6947\u001b[0m  0.0070\n",
      "    110        0.7164       0.4000        \u001b[35m0.6946\u001b[0m  0.0070\n",
      "    111        0.7394       0.4000        \u001b[35m0.6946\u001b[0m  0.0060\n",
      "    112        0.7135       0.4000        \u001b[35m0.6945\u001b[0m  0.0060\n",
      "    113        0.7002       0.4000        \u001b[35m0.6945\u001b[0m  0.0070\n",
      "    114        0.7314       0.4000        \u001b[35m0.6944\u001b[0m  0.0060\n",
      "    115        0.7066       0.4000        \u001b[35m0.6943\u001b[0m  0.0060\n",
      "    116        0.7187       0.4000        \u001b[35m0.6943\u001b[0m  0.0075\n",
      "    117        0.7310       0.4000        \u001b[35m0.6943\u001b[0m  0.0080\n",
      "    118        0.7268       0.4000        \u001b[35m0.6942\u001b[0m  0.0080\n",
      "    119        0.7408       0.4000        \u001b[35m0.6942\u001b[0m  0.0070\n",
      "    120        0.7177       0.4000        \u001b[35m0.6942\u001b[0m  0.0080\n",
      "    121        0.6907       0.4000        \u001b[35m0.6941\u001b[0m  0.0080\n",
      "    122        0.6881       0.4000        \u001b[35m0.6940\u001b[0m  0.0080\n",
      "    123        \u001b[36m0.6246\u001b[0m       0.4000        \u001b[35m0.6940\u001b[0m  0.0079\n",
      "    124        0.6854       0.4000        \u001b[35m0.6939\u001b[0m  0.0080\n",
      "    125        0.6880       0.4000        \u001b[35m0.6939\u001b[0m  0.0080\n",
      "    126        0.7329       0.4000        0.6939  0.0085\n",
      "    127        0.6781       0.4000        \u001b[35m0.6939\u001b[0m  0.0090\n",
      "    128        0.7609       0.4000        \u001b[35m0.6938\u001b[0m  0.0080\n",
      "    129        0.7191       0.4000        \u001b[35m0.6938\u001b[0m  0.0080\n",
      "    130        0.7065       0.4000        \u001b[35m0.6937\u001b[0m  0.0090\n",
      "    131        0.7129       0.4000        \u001b[35m0.6937\u001b[0m  0.0079\n",
      "    132        0.7228       0.4000        \u001b[35m0.6936\u001b[0m  0.0080\n",
      "    133        0.6925       0.4000        \u001b[35m0.6936\u001b[0m  0.0080\n",
      "    134        0.7126       0.4000        \u001b[35m0.6936\u001b[0m  0.0060\n",
      "    135        0.7220       0.4000        0.6936  0.0100\n",
      "    136        0.7222       0.4000        \u001b[35m0.6935\u001b[0m  0.0075\n",
      "    137        0.6854       0.4000        \u001b[35m0.6935\u001b[0m  0.0070\n",
      "    138        0.7637       0.4000        \u001b[35m0.6934\u001b[0m  0.0070\n",
      "    139        0.7186       0.4000        \u001b[35m0.6934\u001b[0m  0.0080\n",
      "    140        0.7214       0.4000        \u001b[35m0.6934\u001b[0m  0.0080\n",
      "    141        0.7235       0.4000        \u001b[35m0.6933\u001b[0m  0.0090\n",
      "    142        0.7401       0.4000        \u001b[35m0.6933\u001b[0m  0.0060\n",
      "    143        0.6791       0.4000        \u001b[35m0.6932\u001b[0m  0.0070\n",
      "    144        0.7392       0.4000        \u001b[35m0.6932\u001b[0m  0.0070\n",
      "    145        0.7550       0.4000        \u001b[35m0.6932\u001b[0m  0.0060\n",
      "    146        0.7152       \u001b[32m0.6000\u001b[0m        \u001b[35m0.6931\u001b[0m  0.0070\n",
      "    147        0.7072       0.6000        \u001b[35m0.6931\u001b[0m  0.0075\n",
      "    148        0.7981       0.6000        \u001b[35m0.6930\u001b[0m  0.0080\n",
      "    149        0.7321       0.6000        \u001b[35m0.6929\u001b[0m  0.0070\n",
      "    150        0.7209       0.6000        \u001b[35m0.6929\u001b[0m  0.0080\n",
      "    151        0.7076       0.6000        \u001b[35m0.6929\u001b[0m  0.0070\n",
      "    152        0.7431       0.6000        \u001b[35m0.6928\u001b[0m  0.0070\n",
      "    153        0.6969       0.6000        \u001b[35m0.6928\u001b[0m  0.0080\n",
      "    154        0.6936       0.6000        \u001b[35m0.6928\u001b[0m  0.0070\n",
      "    155        0.7197       0.6000        \u001b[35m0.6927\u001b[0m  0.0060\n",
      "    156        0.7384       0.6000        \u001b[35m0.6927\u001b[0m  0.0070\n",
      "    157        0.7140       0.6000        \u001b[35m0.6926\u001b[0m  0.0070\n",
      "    158        0.7328       0.6000        \u001b[35m0.6926\u001b[0m  0.0065\n",
      "    159        0.7270       0.6000        \u001b[35m0.6926\u001b[0m  0.0080\n",
      "    160        0.7377       0.6000        \u001b[35m0.6926\u001b[0m  0.0060\n",
      "    161        0.7203       0.6000        \u001b[35m0.6925\u001b[0m  0.0070\n",
      "    162        0.6967       0.6000        \u001b[35m0.6925\u001b[0m  0.0070\n",
      "    163        0.7070       0.6000        \u001b[35m0.6925\u001b[0m  0.0070\n",
      "    164        0.7205       0.6000        \u001b[35m0.6925\u001b[0m  0.0060\n",
      "    165        0.7128       0.6000        0.6925  0.0080\n",
      "    166        0.7741       0.6000        \u001b[35m0.6924\u001b[0m  0.0060\n",
      "    167        0.7633       0.6000        \u001b[35m0.6924\u001b[0m  0.0070\n",
      "    168        0.7090       0.6000        \u001b[35m0.6924\u001b[0m  0.0070\n",
      "    169        0.7362       0.6000        \u001b[35m0.6924\u001b[0m  0.0070\n",
      "    170        0.6693       0.6000        \u001b[35m0.6923\u001b[0m  0.0080\n",
      "    171        0.7331       0.6000        \u001b[35m0.6923\u001b[0m  0.0060\n",
      "    172        0.7418       0.6000        \u001b[35m0.6923\u001b[0m  0.0070\n",
      "    173        0.7861       0.6000        \u001b[35m0.6922\u001b[0m  0.0070\n",
      "    174        0.6894       0.6000        \u001b[35m0.6922\u001b[0m  0.0080\n",
      "    175        0.7400       0.6000        \u001b[35m0.6922\u001b[0m  0.0090\n",
      "    176        0.7012       0.6000        \u001b[35m0.6922\u001b[0m  0.0080\n",
      "    177        0.7361       0.6000        \u001b[35m0.6921\u001b[0m  0.0090\n",
      "    178        0.7335       0.6000        \u001b[35m0.6921\u001b[0m  0.0080\n",
      "    179        0.6875       0.6000        \u001b[35m0.6921\u001b[0m  0.0080\n",
      "    180        0.7348       0.6000        \u001b[35m0.6920\u001b[0m  0.0085\n",
      "    181        0.6802       0.6000        \u001b[35m0.6920\u001b[0m  0.0090\n",
      "    182        0.6973       0.6000        0.6920  0.0100\n",
      "    183        0.7215       0.6000        \u001b[35m0.6920\u001b[0m  0.0070\n",
      "    184        0.6647       0.6000        \u001b[35m0.6919\u001b[0m  0.0070\n",
      "    185        0.7436       0.6000        \u001b[35m0.6919\u001b[0m  0.0070\n",
      "    186        0.7073       0.6000        \u001b[35m0.6919\u001b[0m  0.0070\n",
      "    187        0.7098       0.6000        \u001b[35m0.6918\u001b[0m  0.0080\n",
      "    188        0.7477       0.6000        \u001b[35m0.6918\u001b[0m  0.0080\n",
      "    189        0.6865       0.6000        \u001b[35m0.6918\u001b[0m  0.0100\n",
      "    190        0.7330       0.6000        \u001b[35m0.6918\u001b[0m  0.0095\n",
      "    191        0.7255       0.6000        \u001b[35m0.6917\u001b[0m  0.0080\n",
      "    192        0.6537       0.6000        \u001b[35m0.6917\u001b[0m  0.0060\n",
      "    193        0.7194       0.6000        \u001b[35m0.6916\u001b[0m  0.0070\n",
      "    194        0.8001       0.6000        \u001b[35m0.6916\u001b[0m  0.0060\n",
      "    195        0.7302       0.6000        \u001b[35m0.6916\u001b[0m  0.0060\n",
      "    196        0.7057       0.6000        \u001b[35m0.6916\u001b[0m  0.0080\n",
      "    197        0.7965       0.6000        \u001b[35m0.6915\u001b[0m  0.0060\n",
      "    198        0.7240       0.6000        \u001b[35m0.6915\u001b[0m  0.0070\n",
      "    199        0.6678       0.6000        \u001b[35m0.6915\u001b[0m  0.0070\n",
      "    200        0.7073       0.6000        0.6915  0.0070\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the aptamer-protein pairs\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f00091db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Optional: Evaluate training accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db693e",
   "metadata": {},
   "source": [
    "### Third workflow\n",
    "Dataset balancing using under-sampling, while using your own pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "523f4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you to build your own aptamer pipeline, you should use the following imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "\n",
    "from pyaptamer.aptanet._aptanet_nn import AptaNetMLP\n",
    "from pyaptamer.utils._aptanet_utils import pairs_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cf0bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: If you want to use the Neighborhood Cleaning Rule for under-sampling\n",
    "# NOTE: If you want to use the under-sampling, you need to install imbalanced-learn\n",
    "# and use the Pipeline from imblearn\n",
    "# %pip install imblearn\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13fb1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_transformer = FunctionTransformer(\n",
    "    func=pairs_to_features,\n",
    "    validate=False,\n",
    "    # Optional arguments for pairs_to_features\n",
    "    # example: kw_args={'k': 4, 'pseaac_kwargs': {'lambda_value': 30}}\n",
    "    kw_args={},\n",
    ")\n",
    "\n",
    "selector = SelectFromModel(\n",
    "    estimator=RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=9,\n",
    "        random_state=None,\n",
    "    ),\n",
    "    threshold=\"mean\",\n",
    ")\n",
    "\n",
    "# Define the classifier\n",
    "net = NeuralNetBinaryClassifier(\n",
    "    module=AptaNetMLP,\n",
    "    module__input_dim=None,\n",
    "    module__hidden_dim=128,\n",
    "    module__n_hidden=7,\n",
    "    module__dropout=0.3,\n",
    "    module__output_dim=1,\n",
    "    module__use_lazy=True,\n",
    "    criterion=torch.nn.BCEWithLogitsLoss,\n",
    "    max_epochs=200,\n",
    "    lr=0.00014,\n",
    "    optimizer=torch.optim.RMSprop,\n",
    "    optimizer__alpha=0.9,\n",
    "    optimizer__eps=1e-08,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"features\", feature_transformer),\n",
    "        # Optional under-sampling, use sklearn's Pipeline if you do not need it\n",
    "        (\"ncr\", NeighbourhoodCleaningRule()),\n",
    "        (\"selector\", selector),\n",
    "        (\"clf\", net),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ed76399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7023\u001b[0m       \u001b[32m0.3750\u001b[0m        \u001b[35m0.7047\u001b[0m  0.0115\n",
      "      2        \u001b[36m0.6523\u001b[0m       0.3750        \u001b[35m0.7045\u001b[0m  0.0110\n",
      "      3        0.7088       0.3750        \u001b[35m0.7042\u001b[0m  0.0110\n",
      "      4        0.7553       0.3750        \u001b[35m0.7041\u001b[0m  0.0090\n",
      "      5        0.7432       0.3750        \u001b[35m0.7039\u001b[0m  0.0090\n",
      "      6        0.7215       0.3750        \u001b[35m0.7037\u001b[0m  0.0080\n",
      "      7        0.7044       0.3750        \u001b[35m0.7036\u001b[0m  0.0083\n",
      "      8        0.7064       0.3750        \u001b[35m0.7034\u001b[0m  0.0110\n",
      "      9        0.6890       0.3750        \u001b[35m0.7032\u001b[0m  0.0090\n",
      "     10        0.7676       0.3750        \u001b[35m0.7030\u001b[0m  0.0090\n",
      "     11        0.7384       0.3750        \u001b[35m0.7028\u001b[0m  0.0100\n",
      "     12        0.6737       0.3750        \u001b[35m0.7027\u001b[0m  0.0080\n",
      "     13        0.7397       0.3750        \u001b[35m0.7025\u001b[0m  0.0080\n",
      "     14        0.7553       0.3750        \u001b[35m0.7024\u001b[0m  0.0100\n",
      "     15        0.6919       0.3750        \u001b[35m0.7023\u001b[0m  0.0090\n",
      "     16        0.7337       0.3750        \u001b[35m0.7021\u001b[0m  0.0130\n",
      "     17        0.7426       0.3750        \u001b[35m0.7020\u001b[0m  0.0100\n",
      "     18        0.7592       0.3750        \u001b[35m0.7018\u001b[0m  0.0105\n",
      "     19        0.7078       0.3750        \u001b[35m0.7018\u001b[0m  0.0080\n",
      "     20        0.7358       0.3750        \u001b[35m0.7017\u001b[0m  0.0080\n",
      "     21        0.6586       0.3750        \u001b[35m0.7016\u001b[0m  0.0080\n",
      "     22        0.7606       0.3750        \u001b[35m0.7015\u001b[0m  0.0080\n",
      "     23        0.7891       0.3750        \u001b[35m0.7014\u001b[0m  0.0090\n",
      "     24        0.7144       0.3750        \u001b[35m0.7013\u001b[0m  0.0090\n",
      "     25        0.6975       0.3750        \u001b[35m0.7012\u001b[0m  0.0080\n",
      "     26        0.7578       0.3750        \u001b[35m0.7011\u001b[0m  0.0120\n",
      "     27        0.6601       0.3750        \u001b[35m0.7009\u001b[0m  0.0145\n",
      "     28        0.7574       0.3750        \u001b[35m0.7009\u001b[0m  0.0110\n",
      "     29        0.7666       0.3750        \u001b[35m0.7008\u001b[0m  0.0100\n",
      "     30        0.7646       0.3750        \u001b[35m0.7007\u001b[0m  0.0090\n",
      "     31        0.7055       0.3750        \u001b[35m0.7006\u001b[0m  0.0100\n",
      "     32        0.7826       0.3750        \u001b[35m0.7004\u001b[0m  0.0100\n",
      "     33        0.6706       0.3750        \u001b[35m0.7003\u001b[0m  0.0110\n",
      "     34        0.7404       0.3750        \u001b[35m0.7002\u001b[0m  0.0090\n",
      "     35        0.7340       0.3750        \u001b[35m0.7001\u001b[0m  0.0080\n",
      "     36        0.7449       0.3750        \u001b[35m0.7000\u001b[0m  0.0110\n",
      "     37        0.6893       0.3750        \u001b[35m0.6998\u001b[0m  0.0080\n",
      "     38        0.7040       0.3750        \u001b[35m0.6997\u001b[0m  0.0090\n",
      "     39        0.6701       0.3750        \u001b[35m0.6996\u001b[0m  0.0100\n",
      "     40        \u001b[36m0.6441\u001b[0m       0.3750        \u001b[35m0.6994\u001b[0m  0.0100\n",
      "     41        0.7109       0.3750        \u001b[35m0.6993\u001b[0m  0.0090\n",
      "     42        0.6493       0.3750        \u001b[35m0.6992\u001b[0m  0.0120\n",
      "     43        0.7721       0.3750        \u001b[35m0.6992\u001b[0m  0.0101\n",
      "     44        0.6760       0.3750        \u001b[35m0.6991\u001b[0m  0.0110\n",
      "     45        0.7058       0.3750        \u001b[35m0.6990\u001b[0m  0.0090\n",
      "     46        0.7541       0.3750        \u001b[35m0.6989\u001b[0m  0.0070\n",
      "     47        0.7615       0.3750        \u001b[35m0.6988\u001b[0m  0.0070\n",
      "     48        0.7757       0.3750        \u001b[35m0.6987\u001b[0m  0.0080\n",
      "     49        0.6840       0.3750        \u001b[35m0.6986\u001b[0m  0.0090\n",
      "     50        0.6960       0.3750        \u001b[35m0.6984\u001b[0m  0.0070\n",
      "     51        0.6643       0.3750        \u001b[35m0.6983\u001b[0m  0.0090\n",
      "     52        0.7253       0.3750        \u001b[35m0.6982\u001b[0m  0.0075\n",
      "     53        0.6843       0.3750        \u001b[35m0.6981\u001b[0m  0.0080\n",
      "     54        0.7116       0.3750        \u001b[35m0.6980\u001b[0m  0.0090\n",
      "     55        0.7543       0.3750        \u001b[35m0.6979\u001b[0m  0.0070\n",
      "     56        0.7216       0.3750        \u001b[35m0.6978\u001b[0m  0.0090\n",
      "     57        0.6776       0.3750        \u001b[35m0.6976\u001b[0m  0.0070\n",
      "     58        0.7194       0.3750        \u001b[35m0.6975\u001b[0m  0.0080\n",
      "     59        0.7887       0.3750        \u001b[35m0.6974\u001b[0m  0.0090\n",
      "     60        0.7698       0.3750        \u001b[35m0.6973\u001b[0m  0.0070\n",
      "     61        0.7993       0.3750        \u001b[35m0.6972\u001b[0m  0.0070\n",
      "     62        0.7689       0.3750        \u001b[35m0.6971\u001b[0m  0.0075\n",
      "     63        0.6803       0.3750        \u001b[35m0.6970\u001b[0m  0.0080\n",
      "     64        0.7516       0.3750        \u001b[35m0.6970\u001b[0m  0.0070\n",
      "     65        0.7428       0.3750        \u001b[35m0.6968\u001b[0m  0.0070\n",
      "     66        0.7399       0.3750        \u001b[35m0.6968\u001b[0m  0.0070\n",
      "     67        0.6771       0.3750        \u001b[35m0.6966\u001b[0m  0.0060\n",
      "     68        0.7478       0.3750        \u001b[35m0.6966\u001b[0m  0.0090\n",
      "     69        0.6591       0.3750        \u001b[35m0.6965\u001b[0m  0.0070\n",
      "     70        0.6583       0.3750        \u001b[35m0.6964\u001b[0m  0.0090\n",
      "     71        0.7281       0.3750        \u001b[35m0.6963\u001b[0m  0.0080\n",
      "     72        0.6547       0.3750        \u001b[35m0.6963\u001b[0m  0.0080\n",
      "     73        0.7496       0.3750        \u001b[35m0.6962\u001b[0m  0.0065\n",
      "     74        0.7411       0.3750        \u001b[35m0.6960\u001b[0m  0.0070\n",
      "     75        0.7193       0.3750        \u001b[35m0.6959\u001b[0m  0.0090\n",
      "     76        0.7440       0.3750        \u001b[35m0.6958\u001b[0m  0.0060\n",
      "     77        0.7466       0.3750        \u001b[35m0.6958\u001b[0m  0.0070\n",
      "     78        0.7627       0.3750        \u001b[35m0.6957\u001b[0m  0.0070\n",
      "     79        0.7617       0.3750        \u001b[35m0.6956\u001b[0m  0.0080\n",
      "     80        0.7190       0.3750        \u001b[35m0.6955\u001b[0m  0.0070\n",
      "     81        0.6930       0.3750        \u001b[35m0.6954\u001b[0m  0.0070\n",
      "     82        0.6591       0.3750        \u001b[35m0.6953\u001b[0m  0.0060\n",
      "     83        0.7074       0.3750        \u001b[35m0.6952\u001b[0m  0.0070\n",
      "     84        0.7229       0.3750        \u001b[35m0.6951\u001b[0m  0.0065\n",
      "     85        0.6572       0.3750        \u001b[35m0.6950\u001b[0m  0.0060\n",
      "     86        0.6620       0.3750        \u001b[35m0.6949\u001b[0m  0.0070\n",
      "     87        0.7016       0.3750        \u001b[35m0.6948\u001b[0m  0.0070\n",
      "     88        0.7084       0.3750        \u001b[35m0.6947\u001b[0m  0.0070\n",
      "     89        0.7157       0.3750        \u001b[35m0.6947\u001b[0m  0.0070\n",
      "     90        0.7324       0.3750        \u001b[35m0.6946\u001b[0m  0.0070\n",
      "     91        0.6983       0.3750        \u001b[35m0.6945\u001b[0m  0.0060\n",
      "     92        0.6586       0.3750        \u001b[35m0.6944\u001b[0m  0.0071\n",
      "     93        0.6563       0.3750        \u001b[35m0.6943\u001b[0m  0.0080\n",
      "     94        0.7803       0.3750        \u001b[35m0.6942\u001b[0m  0.0070\n",
      "     95        0.6501       0.3750        \u001b[35m0.6941\u001b[0m  0.0080\n",
      "     96        0.7084       0.3750        \u001b[35m0.6940\u001b[0m  0.0060\n",
      "     97        0.7163       0.3750        \u001b[35m0.6939\u001b[0m  0.0070\n",
      "     98        0.6955       0.3750        \u001b[35m0.6939\u001b[0m  0.0070\n",
      "     99        0.7510       0.3750        \u001b[35m0.6938\u001b[0m  0.0070\n",
      "    100        \u001b[36m0.6188\u001b[0m       0.3750        \u001b[35m0.6937\u001b[0m  0.0090\n",
      "    101        0.7634       0.3750        \u001b[35m0.6937\u001b[0m  0.0080\n",
      "    102        0.6937       0.3750        \u001b[35m0.6936\u001b[0m  0.0090\n",
      "    103        0.6958       0.3750        \u001b[35m0.6936\u001b[0m  0.0060\n",
      "    104        0.6716       0.3750        \u001b[35m0.6935\u001b[0m  0.0070\n",
      "    105        0.7400       0.3750        \u001b[35m0.6934\u001b[0m  0.0100\n",
      "    106        0.7758       0.3750        \u001b[35m0.6933\u001b[0m  0.0085\n",
      "    107        0.7476       0.3750        \u001b[35m0.6932\u001b[0m  0.0060\n",
      "    108        0.7301       \u001b[32m0.6250\u001b[0m        \u001b[35m0.6931\u001b[0m  0.0090\n",
      "    109        0.7752       0.6250        \u001b[35m0.6930\u001b[0m  0.0070\n",
      "    110        0.7350       0.6250        \u001b[35m0.6929\u001b[0m  0.0070\n",
      "    111        0.6598       0.6250        \u001b[35m0.6928\u001b[0m  0.0080\n",
      "    112        0.6919       0.6250        \u001b[35m0.6926\u001b[0m  0.0070\n",
      "    113        0.6862       0.6250        \u001b[35m0.6926\u001b[0m  0.0080\n",
      "    114        0.6767       0.6250        \u001b[35m0.6925\u001b[0m  0.0070\n",
      "    115        0.7185       0.6250        \u001b[35m0.6925\u001b[0m  0.0080\n",
      "    116        0.7491       0.6250        \u001b[35m0.6924\u001b[0m  0.0080\n",
      "    117        0.6230       0.6250        \u001b[35m0.6923\u001b[0m  0.0080\n",
      "    118        0.7047       0.6250        \u001b[35m0.6921\u001b[0m  0.0100\n",
      "    119        0.7683       0.6250        0.6922  0.0110\n",
      "    120        0.6719       0.6250        \u001b[35m0.6921\u001b[0m  0.0080\n",
      "    121        0.6948       0.6250        \u001b[35m0.6920\u001b[0m  0.0070\n",
      "    122        0.6742       0.6250        \u001b[35m0.6919\u001b[0m  0.0110\n",
      "    123        0.7391       0.6250        \u001b[35m0.6918\u001b[0m  0.0080\n",
      "    124        0.7067       0.6250        \u001b[35m0.6917\u001b[0m  0.0070\n",
      "    125        0.7504       0.6250        \u001b[35m0.6916\u001b[0m  0.0090\n",
      "    126        0.7817       0.6250        \u001b[35m0.6915\u001b[0m  0.0105\n",
      "    127        0.8038       0.6250        \u001b[35m0.6914\u001b[0m  0.0070\n",
      "    128        0.7030       0.6250        \u001b[35m0.6914\u001b[0m  0.0100\n",
      "    129        0.6736       0.6250        \u001b[35m0.6913\u001b[0m  0.0090\n",
      "    130        0.6966       0.6250        \u001b[35m0.6912\u001b[0m  0.0080\n",
      "    131        0.7133       0.6250        \u001b[35m0.6910\u001b[0m  0.0070\n",
      "    132        0.7456       0.6250        \u001b[35m0.6909\u001b[0m  0.0070\n",
      "    133        0.6968       0.6250        \u001b[35m0.6908\u001b[0m  0.0080\n",
      "    134        0.6665       0.6250        \u001b[35m0.6907\u001b[0m  0.0070\n",
      "    135        0.6886       0.6250        \u001b[35m0.6906\u001b[0m  0.0070\n",
      "    136        0.7258       0.6250        \u001b[35m0.6905\u001b[0m  0.0090\n",
      "    137        0.6810       0.6250        \u001b[35m0.6904\u001b[0m  0.0080\n",
      "    138        0.6946       0.6250        \u001b[35m0.6902\u001b[0m  0.0060\n",
      "    139        0.7383       0.6250        \u001b[35m0.6901\u001b[0m  0.0090\n",
      "    140        0.7272       0.6250        \u001b[35m0.6900\u001b[0m  0.0080\n",
      "    141        0.6727       0.6250        \u001b[35m0.6899\u001b[0m  0.0080\n",
      "    142        0.6801       0.6250        \u001b[35m0.6898\u001b[0m  0.0100\n",
      "    143        0.6598       0.6250        \u001b[35m0.6897\u001b[0m  0.0110\n",
      "    144        0.6659       0.6250        \u001b[35m0.6895\u001b[0m  0.0070\n",
      "    145        0.7729       0.6250        \u001b[35m0.6895\u001b[0m  0.0065\n",
      "    146        0.6883       0.6250        \u001b[35m0.6894\u001b[0m  0.0070\n",
      "    147        0.6506       0.6250        \u001b[35m0.6893\u001b[0m  0.0090\n",
      "    148        0.6696       0.6250        \u001b[35m0.6893\u001b[0m  0.0090\n",
      "    149        0.7557       0.6250        \u001b[35m0.6892\u001b[0m  0.0070\n",
      "    150        0.7007       0.6250        \u001b[35m0.6891\u001b[0m  0.0070\n",
      "    151        0.6511       0.6250        \u001b[35m0.6890\u001b[0m  0.0080\n",
      "    152        0.7153       0.6250        \u001b[35m0.6889\u001b[0m  0.0080\n",
      "    153        0.6870       0.6250        \u001b[35m0.6888\u001b[0m  0.0070\n",
      "    154        0.6999       0.6250        \u001b[35m0.6887\u001b[0m  0.0070\n",
      "    155        0.7244       0.6250        \u001b[35m0.6886\u001b[0m  0.0080\n",
      "    156        0.6536       0.6250        \u001b[35m0.6886\u001b[0m  0.0065\n",
      "    157        0.6521       0.6250        \u001b[35m0.6885\u001b[0m  0.0060\n",
      "    158        0.7016       0.6250        \u001b[35m0.6884\u001b[0m  0.0070\n",
      "    159        0.6258       0.6250        \u001b[35m0.6884\u001b[0m  0.0080\n",
      "    160        0.6334       0.6250        \u001b[35m0.6883\u001b[0m  0.0070\n",
      "    161        0.6815       0.6250        \u001b[35m0.6882\u001b[0m  0.0060\n",
      "    162        0.7057       0.6250        \u001b[35m0.6881\u001b[0m  0.0060\n",
      "    163        0.6695       0.6250        \u001b[35m0.6880\u001b[0m  0.0090\n",
      "    164        0.7227       0.6250        \u001b[35m0.6879\u001b[0m  0.0060\n",
      "    165        0.7268       0.6250        \u001b[35m0.6877\u001b[0m  0.0080\n",
      "    166        0.7293       0.6250        \u001b[35m0.6876\u001b[0m  0.0070\n",
      "    167        0.6670       0.6250        \u001b[35m0.6875\u001b[0m  0.0070\n",
      "    168        0.6942       0.6250        \u001b[35m0.6874\u001b[0m  0.0080\n",
      "    169        0.7761       0.6250        \u001b[35m0.6874\u001b[0m  0.0070\n",
      "    170        0.7003       0.6250        \u001b[35m0.6873\u001b[0m  0.0090\n",
      "    171        0.6726       0.6250        \u001b[35m0.6872\u001b[0m  0.0070\n",
      "    172        0.6750       0.6250        \u001b[35m0.6872\u001b[0m  0.0110\n",
      "    173        0.6262       0.6250        \u001b[35m0.6870\u001b[0m  0.0070\n",
      "    174        0.6379       0.6250        \u001b[35m0.6869\u001b[0m  0.0070\n",
      "    175        0.6475       0.6250        \u001b[35m0.6869\u001b[0m  0.0080\n",
      "    176        0.6707       0.6250        \u001b[35m0.6868\u001b[0m  0.0070\n",
      "    177        0.6932       0.6250        \u001b[35m0.6867\u001b[0m  0.0070\n",
      "    178        0.7285       0.6250        \u001b[35m0.6866\u001b[0m  0.0055\n",
      "    179        0.7109       0.6250        \u001b[35m0.6865\u001b[0m  0.0070\n",
      "    180        0.6546       0.6250        \u001b[35m0.6864\u001b[0m  0.0100\n",
      "    181        0.7654       0.6250        \u001b[35m0.6864\u001b[0m  0.0070\n",
      "    182        0.7428       0.6250        \u001b[35m0.6863\u001b[0m  0.0110\n",
      "    183        0.6780       0.6250        \u001b[35m0.6862\u001b[0m  0.0120\n",
      "    184        0.6689       0.6250        \u001b[35m0.6861\u001b[0m  0.0101\n",
      "    185        0.6795       0.6250        \u001b[35m0.6860\u001b[0m  0.0079\n",
      "    186        0.7632       0.6250        \u001b[35m0.6859\u001b[0m  0.0060\n",
      "    187        0.6936       0.6250        \u001b[35m0.6858\u001b[0m  0.0070\n",
      "    188        0.6430       0.6250        \u001b[35m0.6858\u001b[0m  0.0060\n",
      "    189        0.6438       0.6250        \u001b[35m0.6857\u001b[0m  0.0080\n",
      "    190        0.6974       0.6250        \u001b[35m0.6856\u001b[0m  0.0060\n",
      "    191        0.6550       0.6250        \u001b[35m0.6856\u001b[0m  0.0080\n",
      "    192        0.7158       0.6250        \u001b[35m0.6855\u001b[0m  0.0060\n",
      "    193        0.6552       0.6250        \u001b[35m0.6854\u001b[0m  0.0090\n",
      "    194        0.6752       0.6250        \u001b[35m0.6852\u001b[0m  0.0070\n",
      "    195        0.6674       0.6250        \u001b[35m0.6852\u001b[0m  0.0070\n",
      "    196        0.7151       0.6250        \u001b[35m0.6851\u001b[0m  0.0060\n",
      "    197        0.7591       0.6250        \u001b[35m0.6850\u001b[0m  0.0070\n",
      "    198        0.6578       0.6250        \u001b[35m0.6849\u001b[0m  0.0090\n",
      "    199        0.6989       0.6250        \u001b[35m0.6848\u001b[0m  0.0065\n",
      "    200        0.6693       0.6250        \u001b[35m0.6848\u001b[0m  0.0080\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the aptamer-protein pairs\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Predict the labels for the training data\n",
    "y_pred = pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "945dc876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.46\n"
     ]
    }
   ],
   "source": [
    "# Optional: Evaluate training accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyaptamer-latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
